    "# # SciPy: Scientific Computing in Python\n",
    "# \n",
    "# ## Introduction\n",
    "# \n",
    "# SciPy (Scientific Python) is a collection of mathematical algorithms and convenience functions built on the NumPy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data.\n",
    "# \n",
    "# SciPy contains modules for:\n",
    "# \n",
    "# - Optimization\n",
    "# - Linear Algebra\n",
    "# - Integration\n",
    "# - Interpolation\n",
    "# - Signal and Image Processing\n",
    "# - Ordinary Differential Equation (ODE) Solvers\n",
    "# - Statistical Functions\n",
    "# - Spatial Data Structures and Algorithms\n",
    "# - and more...\n",
    "# \n",
    "# This section will introduce you to the most essential SciPy modules and functions that are widely used in machine learning and scientific computing.\n",
    "# \n",
    "# **Source:** [SciPy Documentation](https://docs.scipy.org/doc/scipy/reference/) and [SciPy GitHub Repository](https://github.com/scipy/scipy)\n",
    "\n",
    "# ## Why SciPy?\n",
    "# \n",
    "# SciPy builds on NumPy and provides additional functionality for more specialized scientific computing tasks. While NumPy provides the fundamental array data structure and basic operations, SciPy offers domain-specific functions that would otherwise require custom implementations.\n",
    "# \n",
    "# Key advantages of SciPy include:\n",
    "# \n",
    "# - Efficient implementations of scientific algorithms\n",
    "# - Built on NumPy, providing seamless integration\n",
    "# - Well-tested and maintained by a large community\n",
    "# - Reduces the need to write custom implementations for common scientific tasks\n",
    "# - Enables faster development of scientific applications\n",
    "# \n",
    "# **Source:** [Scientific Python Lectures](https://github.com/jrjohansson/scientific-python-lectures)\n",
    "\n",
    "# ## 1. SciPy Optimization (`scipy.optimize`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "\n",
    "# Set the style for plots\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "# ### 1.1 Function Minimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to minimize\n",
    "def f(x):\n",
    "    return x**2 + 10*np.sin(x)\n",
    "\n",
    "# Plot the function\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, f(x))\n",
    "plt.grid(True)\n",
    "plt.title('f(x) = x² + 10sin(x)', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('f(x)', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Find the minimum using different methods\n",
    "methods = ['Nelder-Mead', 'BFGS', 'CG', 'Powell']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    result = optimize.minimize(f, x0=0, method=method)\n",
    "    results[method] = {\n",
    "        'x': result.x[0],\n",
    "        'fun': result.fun,\n",
    "        'success': result.success,\n",
    "        'iterations': result.nit,\n",
    "        'function_evaluations': result.nfev\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Optimization Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, f(x), 'b-', linewidth=2, label='f(x)')\n",
    "\n",
    "for method, result in results.items():\n",
    "    plt.plot(result['x'], result['fun'], 'o', markersize=10, label=f\"{method}: x={result['x']:.4f}, f(x)={result['fun']:.4f}\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title('Optimization Results for Different Methods', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('f(x)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 1.2 Root Finding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to find roots\n",
    "def g(x):\n",
    "    return x**3 - 2*x**2 - 11*x + 12\n",
    "\n",
    "# Plot the function\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, g(x))\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "plt.title('g(x) = x³ - 2x² - 11x + 12', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('g(x)', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Find roots using different methods\n",
    "root1 = optimize.root_scalar(g, bracket=[-5, -2], method='brentq')\n",
    "root2 = optimize.root_scalar(g, bracket=[-2, 2], method='brentq')\n",
    "root3 = optimize.root_scalar(g, bracket=[2, 5], method='brentq')\n",
    "\n",
    "print(\"Root 1:\", root1.root)\n",
    "print(\"Root 2:\", root2.root)\n",
    "print(\"Root 3:\", root3.root)\n",
    "\n",
    "# Verify the roots\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"g({root1.root:.4f}) = {g(root1.root):.10f}\")\n",
    "print(f\"g({root2.root:.4f}) = {g(root2.root):.10f}\")\n",
    "print(f\"g({root3.root:.4f}) = {g(root3.root):.10f}\")\n",
    "\n",
    "# Visualize the roots\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, g(x), 'b-', linewidth=2, label='g(x)')\n",
    "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "\n",
    "roots = [root1.root, root2.root, root3.root]\n",
    "for i, root in enumerate(roots):\n",
    "    plt.plot(root, g(root), 'o', markersize=10, label=f\"Root {i+1}: x={root:.4f}\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title('Roots of g(x) = x³ - 2x² - 11x + 12', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('g(x)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 1.3 Curve Fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af2dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate some noisy data\n",
    "np.random.seed(42)\n",
    "x_data = np.linspace(0, 10, 20)\n",
    "y_true = 3.5 * np.sin(1.5 * x_data) + 4.2\n",
    "y_noise = 0.8 * np.random.normal(size=x_data.size)\n",
    "y_data = y_true + y_noise\n",
    "\n",
    "# Define the model function\n",
    "def model_func(x, a, b, c):\n",
    "    return a * np.sin(b * x) + c\n",
    "\n",
    "# Fit the model to the data\n",
    "params, params_covariance = optimize.curve_fit(model_func, x_data, y_data, p0=[2, 1, 4])\n",
    "\n",
    "print(\"Fitted parameters:\")\n",
    "print(f\"a = {params[0]:.4f}\")\n",
    "print(f\"b = {params[1]:.4f}\")\n",
    "print(f\"c = {params[2]:.4f}\")\n",
    "\n",
    "# Calculate the fitted curve\n",
    "x_fit = np.linspace(0, 10, 1000)\n",
    "y_fit = model_func(x_fit, params[0], params[1], params[2])\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(x_data, y_data, label='Data with noise')\n",
    "plt.plot(x_fit, y_fit, 'r-', linewidth=2, label='Fitted curve')\n",
    "plt.plot(x_fit, 3.5 * np.sin(1.5 * x_fit) + 4.2, 'g--', linewidth=2, label='True curve')\n",
    "plt.grid(True)\n",
    "plt.title('Curve Fitting Example', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 1.4 Constrained Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdaaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to minimize\n",
    "def objective(x):\n",
    "    return (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
    "\n",
    "# Define constraints\n",
    "def constraint1(x):\n",
    "    return x[0] - 2*x[1] + 2  # x[0] - 2*x[1] + 2 >= 0\n",
    "\n",
    "def constraint2(x):\n",
    "    return -x[0] - 2*x[1] + 6  # -x[0] - 2*x[1] + 6 >= 0\n",
    "\n",
    "def constraint3(x):\n",
    "    return -x[0] + 2*x[1] + 2  # -x[0] + 2*x[1] + 2 >= 0\n",
    "\n",
    "def constraint4(x):\n",
    "    return x[0]  # x[0] >= 0\n",
    "\n",
    "def constraint5(x):\n",
    "    return x[1]  # x[1] >= 0\n",
    "\n",
    "# Define bounds\n",
    "bounds = ((0, None), (0, None))\n",
    "\n",
    "# Define constraints as dictionary\n",
    "constraints = (\n",
    "    {'type': 'ineq', 'fun': constraint1},\n",
    "    {'type': 'ineq', 'fun': constraint2},\n",
    "    {'type': 'ineq', 'fun': constraint3},\n",
    "    {'type': 'ineq', 'fun': constraint4},\n",
    "    {'type': 'ineq', 'fun': constraint5}\n",
    ")\n",
    "\n",
    "# Initial guess\n",
    "x0 = [1, 1]\n",
    "\n",
    "# Solve the constrained optimization problem\n",
    "result = optimize.minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "print(\"Optimization Result:\")\n",
    "print(f\"x = {result.x}\")\n",
    "print(f\"f(x) = {result.fun}\")\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Message: {result.message}\")\n",
    "\n",
    "# Visualize the constraints and solution\n",
    "x1 = np.linspace(-1, 4, 100)\n",
    "x2 = np.linspace(-1, 4, 100)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "Z = np.zeros_like(X1)\n",
    "\n",
    "for i in range(X1.shape[0]):\n",
    "    for j in range(X1.shape[1]):\n",
    "        Z[i, j] = objective([X1[i, j], X2[i, j]])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot the objective function contours\n",
    "plt.contourf(X1, X2, Z, 50, alpha=0.5, cmap='viridis')\n",
    "plt.colorbar(label='Objective function value')\n",
    "\n",
    "# Plot the constraints\n",
    "x1_vals = np.linspace(0, 4, 100)\n",
    "plt.plot(x1_vals, (x1_vals + 2) / 2, 'r-', linewidth=2, label='Constraint 1')\n",
    "plt.plot(x1_vals, (6 - x1_vals) / 2, 'g-', linewidth=2, label='Constraint 2')\n",
    "plt.plot(x1_vals, (x1_vals - 2) / 2, 'b-', linewidth=2, label='Constraint 3')\n",
    "plt.axvline(x=0, color='m', linestyle='-', linewidth=2, label='Constraint 4')\n",
    "plt.axhline(y=0, color='c', linestyle='-', linewidth=2, label='Constraint 5')\n",
    "\n",
    "# Highlight the feasible region\n",
    "x1_region = np.linspace(0, 2, 100)\n",
    "x2_region1 = (x1_region + 2) / 2\n",
    "x2_region2 = (6 - x1_region) / 2\n",
    "plt.fill_between(x1_region, x2_region1, x2_region2, where=(x2_region1 <= x2_region2), \n",
    "                 alpha=0.2, color='gray', label='Feasible Region')\n",
    "\n",
    "# Plot the solution\n",
    "plt.scatter(result.x[0], result.x[1], s=100, c='red', marker='*', label='Solution')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title('Constrained Optimization', fontsize=16)\n",
    "plt.xlabel('x₁', fontsize=14)\n",
    "plt.ylabel('x₂', fontsize=14)\n",
    "plt.legend()\n",
    "plt.xlim(-0.5, 4)\n",
    "plt.ylim(-0.5, 4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ## 2. SciPy Linear Algebra (`scipy.linalg`)\n",
    "\n",
    "# ### 2.1 Basic Linear Algebra Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b806bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "# Create a sample matrix\n",
    "A = np.array([[3, 2, 0], [1, -1, 0], [0, 5, 1]])\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "\n",
    "# Compute the determinant\n",
    "det_A = linalg.det(A)\n",
    "print(\"\\nDeterminant of A:\", det_A)\n",
    "\n",
    "# Compute the inverse\n",
    "inv_A = linalg.inv(A)\n",
    "print(\"\\nInverse of A:\")\n",
    "print(inv_A)\n",
    "\n",
    "# Verify A * A^(-1) = I\n",
    "print(\"\\nA * A^(-1):\")\n",
    "print(np.round(A @ inv_A, decimals=10))  # Should be close to the identity matrix\n",
    "\n",
    "# Compute the norm\n",
    "norm_A = linalg.norm(A)\n",
    "print(\"\\nFrobenius norm of A:\", norm_A)\n",
    "\n",
    "# Compute the condition number\n",
    "cond_A = linalg.cond(A)\n",
    "print(\"\\nCondition number of A:\", cond_A)\n",
    "\n",
    "\n",
    "# ### 2.2 Solving Linear Systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a system of linear equations: Ax = b\n",
    "A = np.array([[3, 2, 0], [1, -1, 0], [0, 5, 1]])\n",
    "b = np.array([2, 4, -1])\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nVector b:\", b)\n",
    "\n",
    "# Solve the system using scipy.linalg.solve\n",
    "x = linalg.solve(A, b)\n",
    "print(\"\\nSolution x:\", x)\n",
    "\n",
    "# Verify the solution\n",
    "print(\"\\nA @ x:\", A @ x)\n",
    "print(\"Should be equal to b:\", b)\n",
    "\n",
    "# Solve using LU decomposition\n",
    "lu, piv = linalg.lu_factor(A)\n",
    "x_lu = linalg.lu_solve((lu, piv), b)\n",
    "print(\"\\nSolution using LU decomposition:\", x_lu)\n",
    "\n",
    "# Solve using the pseudoinverse for overdetermined or underdetermined systems\n",
    "A_rect = np.array([[3, 2], [1, -1], [0, 5]])  # 3x2 matrix (overdetermined)\n",
    "b_rect = np.array([2, 4, -1])\n",
    "\n",
    "# Compute the pseudoinverse\n",
    "A_pinv = linalg.pinv(A_rect)\n",
    "print(\"\\nPseudoinverse of rectangular A:\")\n",
    "print(A_pinv)\n",
    "\n",
    "# Solve the overdetermined system\n",
    "x_pinv = A_pinv @ b_rect\n",
    "print(\"\\nLeast-squares solution for overdetermined system:\", x_pinv)\n",
    "\n",
    "# Verify the solution (should minimize ||Ax - b||)\n",
    "print(\"\\nA_rect @ x_pinv:\", A_rect @ x_pinv)\n",
    "print(\"Original b_rect:\", b_rect)\n",
    "\n",
    "\n",
    "# ### 2.3 Eigenvalues and Eigenvectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b07b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a sample matrix\n",
    "A = np.array([[4, -2, 1], [1, 1, 1], [1, 2, 3]])\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = linalg.eig(A)\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(\"\\nEigenvectors (by column):\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Verify Av = λv for the first eigenpair\n",
    "v1 = eigenvectors[:, 0]\n",
    "lambda1 = eigenvalues[0]\n",
    "print(\"\\nVerification for first eigenpair:\")\n",
    "print(\"A @ v1:\", A @ v1)\n",
    "print(\"λ1 * v1:\", lambda1 * v1)\n",
    "\n",
    "# Compute only eigenvalues\n",
    "eigenvalues_only = linalg.eigvals(A)\n",
    "print(\"\\nEigenvalues (computed directly):\")\n",
    "print(eigenvalues_only)\n",
    "\n",
    "# Compute the matrix exponential\n",
    "exp_A = linalg.expm(A)\n",
    "print(\"\\nMatrix exponential of A:\")\n",
    "print(exp_A)\n",
    "\n",
    "# Compute the matrix logarithm\n",
    "log_A = linalg.logm(A)\n",
    "print(\"\\nMatrix logarithm of A:\")\n",
    "print(log_A)\n",
    "\n",
    "# Verify exp(log(A)) ≈ A\n",
    "print(\"\\nexp(log(A)):\")\n",
    "print(linalg.expm(log_A))\n",
    "print(\"Should be approximately equal to A:\")\n",
    "print(A)\n",
    "\n",
    "\n",
    "# ### 2.4 Singular Value Decomposition (SVD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a sample matrix\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "\n",
    "# Compute the SVD\n",
    "U, s, Vh = linalg.svd(A)\n",
    "\n",
    "print(\"\\nU matrix (left singular vectors):\")\n",
    "print(U)\n",
    "\n",
    "print(\"\\nSingular values:\")\n",
    "print(s)\n",
    "\n",
    "print(\"\\nVh matrix (right singular vectors, transposed):\")\n",
    "print(Vh)\n",
    "\n",
    "# Verify the decomposition: A = U @ Sigma @ Vh\n",
    "# First, create the Sigma matrix\n",
    "Sigma = np.zeros((A.shape[0], A.shape[1]))\n",
    "np.fill_diagonal(Sigma, s)\n",
    "\n",
    "print(\"\\nSigma matrix:\")\n",
    "print(Sigma)\n",
    "\n",
    "# Reconstruct A\n",
    "A_reconstructed = U @ Sigma @ Vh\n",
    "print(\"\\nReconstructed A:\")\n",
    "print(A_reconstructed)\n",
    "print(\"Should be equal to the original A:\")\n",
    "print(A)\n",
    "\n",
    "# Low-rank approximation\n",
    "k = 2  # Number of singular values to keep\n",
    "Sigma_k = np.zeros((A.shape[0], A.shape[1]))\n",
    "np.fill_diagonal(Sigma_k, s[:k])\n",
    "\n",
    "A_k = U @ Sigma_k @ Vh\n",
    "print(\"\\nRank-2 approximation of A:\")\n",
    "print(A_k)\n",
    "\n",
    "# Visualize the original matrix and its low-rank approximation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].imshow(A, cmap='viridis')\n",
    "axes[0].set_title('Original Matrix', fontsize=14)\n",
    "axes[0].set_xlabel('Column', fontsize=12)\n",
    "axes[0].set_ylabel('Row', fontsize=12)\n",
    "\n",
    "axes[1].imshow(A_k, cmap='viridis')\n",
    "axes[1].set_title(f'Rank-{k} Approximation', fontsize=14)\n",
    "axes[1].set_xlabel('Column', fontsize=12)\n",
    "axes[1].set_ylabel('Row', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute the pseudoinverse using SVD\n",
    "A_pinv = linalg.pinv(A)\n",
    "print(\"\\nPseudoinverse of A:\")\n",
    "print(A_pinv)\n",
    "\n",
    "# Verify A @ A_pinv @ A = A\n",
    "print(\"\\nA @ A_pinv @ A:\")\n",
    "print(A @ A_pinv @ A)\n",
    "print(\"Should be equal to A:\")\n",
    "print(A)\n",
    "\n",
    "\n",
    "# ## 3. SciPy Integration and Differential Equations\n",
    "\n",
    "# ### 3.1 Numerical Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import integrate\n",
    "\n",
    "# Define a function to integrate\n",
    "def f(x):\n",
    "    return x**2 * np.exp(-x)\n",
    "\n",
    "# Definite integral from 0 to 4\n",
    "result, error = integrate.quad(f, 0, 4)\n",
    "print(f\"∫₀⁴ x² e^(-x) dx = {result} ± {error}\")\n",
    "\n",
    "# Plot the function and the integral\n",
    "x = np.linspace(0, 4, 1000)\n",
    "y = f(x)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, 'b-', linewidth=2, label='f(x) = x² e^(-x)')\n",
    "plt.fill_between(x, 0, y, alpha=0.3, color='blue')\n",
    "plt.grid(True)\n",
    "plt.title('Numerical Integration Example', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('f(x)', fontsize=14)\n",
    "plt.text(2, 0.5, f'∫₀⁴ f(x) dx = {result:.6f}', fontsize=14, bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Multiple integration\n",
    "def g(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "# Double integral over a rectangular region\n",
    "result, error = integrate.dblquad(g, 0, 2, lambda x: 0, lambda x: 1)\n",
    "print(f\"∫₀¹ ∫₀² (x² + y²) dx dy = {result} ± {error}\")\n",
    "\n",
    "# Triple integral\n",
    "def h(x, y, z):\n",
    "    return x**2 + y**2 + z**2\n",
    "\n",
    "# Triple integral over a rectangular region\n",
    "result, error = integrate.tplquad(h, 0, 1, lambda x: 0, lambda x: 1, lambda x, y: 0, lambda x, y: 1)\n",
    "print(f\"∫₀¹ ∫₀¹ ∫₀¹ (x² + y² + z²) dx dy dz = {result} ± {error}\")\n",
    "\n",
    "\n",
    "# ### 3.2 Ordinary Differential Equations (ODEs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example 1: Simple first-order ODE\n",
    "# dy/dt = -k*y, y(0) = 1\n",
    "# Analytical solution: y(t) = exp(-k*t)\n",
    "\n",
    "def exponential_decay(t, y, k):\n",
    "    return -k * y\n",
    "\n",
    "# Parameters\n",
    "k = 0.3  # decay constant\n",
    "y0 = 1.0  # initial condition\n",
    "t_span = (0, 10)  # time span\n",
    "t_eval = np.linspace(0, 10, 100)  # points to evaluate the solution\n",
    "\n",
    "# Solve the ODE\n",
    "solution = integrate.solve_ivp(exponential_decay, t_span, [y0], args=(k,), t_eval=t_eval)\n",
    "\n",
    "# Plot the solution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(solution.t, solution.y[0], 'b-', linewidth=2, label='Numerical solution')\n",
    "plt.plot(solution.t, np.exp(-k * solution.t), 'r--', linewidth=2, label='Analytical solution: exp(-kt)')\n",
    "plt.grid(True)\n",
    "plt.title('Solution of dy/dt = -k*y with y(0) = 1', fontsize=16)\n",
    "plt.xlabel('t', fontsize=14)\n",
    "plt.ylabel('y(t)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Example 2: System of ODEs - Lotka-Volterra (Predator-Prey) model\n",
    "# dx/dt = αx - βxy\n",
    "# dy/dt = δxy - γy\n",
    "\n",
    "def lotka_volterra(t, z, alpha, beta, gamma, delta):\n",
    "    x, y = z\n",
    "    dx_dt = alpha * x - beta * x * y\n",
    "    dy_dt = delta * x * y - gamma * y\n",
    "    return [dx_dt, dy_dt]\n",
    "\n",
    "# Parameters\n",
    "alpha = 1.0  # growth rate of prey\n",
    "beta = 0.1   # rate at which predators kill prey\n",
    "gamma = 1.5  # death rate of predators\n",
    "delta = 0.075  # rate at which predators increase by consuming prey\n",
    "\n",
    "# Initial conditions\n",
    "z0 = [10, 5]  # initial populations of prey and predators\n",
    "t_span = (0, 40)  # time span\n",
    "t_eval = np.linspace(0, 40, 1000)  # points to evaluate the solution\n",
    "\n",
    "# Solve the system of ODEs\n",
    "solution = integrate.solve_ivp(\n",
    "    lotka_volterra, t_span, z0, args=(alpha, beta, gamma, delta), \n",
    "    method='RK45', t_eval=t_eval\n",
    ")\n",
    "\n",
    "# Plot the solution\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Population vs time\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solution.t, solution.y[0], 'b-', linewidth=2, label='Prey (x)')\n",
    "plt.plot(solution.t, solution.y[1], 'r-', linewidth=2, label='Predator (y)')\n",
    "plt.grid(True)\n",
    "plt.title('Lotka-Volterra Model: Population vs Time', fontsize=16)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('Population', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "# Phase plane\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solution.y[0], solution.y[1], 'g-', linewidth=2)\n",
    "plt.plot(solution.y[0][0], solution.y[1][0], 'ko', markersize=10, label='Initial state')\n",
    "plt.grid(True)\n",
    "plt.title('Lotka-Volterra Model: Phase Plane', fontsize=16)\n",
    "plt.xlabel('Prey Population (x)', fontsize=14)\n",
    "plt.ylabel('Predator Population (y)', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 3.3 Interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c82c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "# Generate some data points\n",
    "np.random.seed(42)\n",
    "x = np.sort(np.random.random(10) * 10)\n",
    "y = np.sin(x) + 0.2 * np.random.randn(10)\n",
    "\n",
    "# Create a fine grid for plotting\n",
    "x_fine = np.linspace(0, 10, 1000)\n",
    "\n",
    "# Linear interpolation\n",
    "f_linear = interpolate.interp1d(x, y, kind='linear')\n",
    "y_linear = f_linear(x_fine)\n",
    "\n",
    "# Cubic interpolation\n",
    "f_cubic = interpolate.interp1d(x, y, kind='cubic')\n",
    "y_cubic = f_cubic(x_fine)\n",
    "\n",
    "# Spline interpolation\n",
    "tck = interpolate.splrep(x, y, s=0)\n",
    "y_spline = interpolate.splev(x_fine, tck, der=0)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(x, y, c='k', s=50, label='Data points')\n",
    "plt.plot(x_fine, y_linear, 'r-', linewidth=2, label='Linear interpolation')\n",
    "plt.plot(x_fine, y_cubic, 'g-', linewidth=2, label='Cubic interpolation')\n",
    "plt.plot(x_fine, y_spline, 'b-', linewidth=2, label='Spline interpolation')\n",
    "plt.plot(x_fine, np.sin(x_fine), 'k--', linewidth=1, label='True function: sin(x)')\n",
    "plt.grid(True)\n",
    "plt.title('Interpolation Methods Comparison', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2D interpolation\n",
    "# Generate a 2D grid of points\n",
    "x = np.linspace(-3, 3, 10)\n",
    "y = np.linspace(-3, 3, 10)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.sin(X**2 + Y**2)\n",
    "\n",
    "# Create a finer grid for interpolation\n",
    "x_fine = np.linspace(-3, 3, 100)\n",
    "y_fine = np.linspace(-3, 3, 100)\n",
    "X_fine, Y_fine = np.meshgrid(x_fine, y_fine)\n",
    "\n",
    "# Perform 2D interpolation\n",
    "f = interpolate.interp2d(x, y, Z, kind='cubic')\n",
    "Z_interp = f(x_fine, y_fine)\n",
    "\n",
    "# Plot the original data and the interpolation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6), subplot_kw={'projection': '3d'})\n",
    "\n",
    "# Original data\n",
    "axes[0].plot_surface(X, Y, Z, cmap='viridis', edgecolor='none')\n",
    "axes[0].set_title('Original Data', fontsize=14)\n",
    "axes[0].set_xlabel('X', fontsize=12)\n",
    "axes[0].set_ylabel('Y', fontsize=12)\n",
    "axes[0].set_zlabel('Z', fontsize=12)\n",
    "\n",
    "# Interpolated data\n",
    "axes[1].plot_surface(X_fine, Y_fine, Z_interp, cmap='viridis', edgecolor='none')\n",
    "axes[1].set_title('Cubic Interpolation', fontsize=14)\n",
    "axes[1].set_xlabel('X', fontsize=12)\n",
    "axes[1].set_ylabel('Y', fontsize=12)\n",
    "axes[1].set_zlabel('Z', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ## 4. SciPy Signal Processing (`scipy.signal`)\n",
    "\n",
    "# ### 4.1 Filtering and Convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f52e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "# Generate a noisy signal\n",
    "np.random.seed(42)\n",
    "t = np.linspace(0, 1, 1000, endpoint=False)\n",
    "clean_signal = np.sin(2 * np.pi * 5 * t) + 0.5 * np.sin(2 * np.pi * 20 * t)\n",
    "noise = 0.5 * np.random.normal(size=t.size)\n",
    "noisy_signal = clean_signal + noise\n",
    "\n",
    "# Design a Butterworth low-pass filter\n",
    "b, a = signal.butter(4, 0.1, 'low', analog=False)\n",
    "\n",
    "# Apply the filter\n",
    "filtered_signal = signal.filtfilt(b, a, noisy_signal)\n",
    "\n",
    "# Plot the signals\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t, clean_signal, 'g-', linewidth=2, label='Clean signal')\n",
    "plt.grid(True)\n",
    "plt.title('Original Clean Signal', fontsize=14)\n",
    "plt.xlabel('Time [s]', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(t, noisy_signal, 'b-', linewidth=1, label='Noisy signal')\n",
    "plt.grid(True)\n",
    "plt.title('Noisy Signal', fontsize=14)\n",
    "plt.xlabel('Time [s]', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(t, filtered_signal, 'r-', linewidth=2, label='Filtered signal')\n",
    "plt.grid(True)\n",
    "plt.title('Filtered Signal', fontsize=14)\n",
    "plt.xlabel('Time [s]', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Convolution example\n",
    "# Create a square pulse signal\n",
    "t = np.linspace(-1, 1, 201)\n",
    "square_pulse = np.zeros_like(t)\n",
    "square_pulse[(t >= -0.5) & (t <= 0.5)] = 1\n",
    "\n",
    "# Create a Gaussian kernel\n",
    "sigma = 0.1\n",
    "gaussian_kernel = np.exp(-(t**2) / (2 * sigma**2))\n",
    "gaussian_kernel /= np.sum(gaussian_kernel)  # Normalize\n",
    "\n",
    "# Convolve the square pulse with the Gaussian kernel\n",
    "convolved_signal = signal.convolve(square_pulse, gaussian_kernel, mode='same')\n",
    "\n",
    "# Plot the signals\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t, square_pulse, 'b-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('Square Pulse Signal', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(t, gaussian_kernel, 'r-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('Gaussian Kernel', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(t, convolved_signal, 'g-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('Convolved Signal', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 4.2 Spectral Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bcd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate a signal with multiple frequency components\n",
    "t = np.linspace(0, 1, 1000, endpoint=False)\n",
    "signal_1 = np.sin(2 * np.pi * 5 * t)  # 5 Hz component\n",
    "signal_2 = 0.5 * np.sin(2 * np.pi * 20 * t)  # 20 Hz component\n",
    "signal_3 = 0.2 * np.sin(2 * np.pi * 50 * t)  # 50 Hz component\n",
    "composite_signal = signal_1 + signal_2 + signal_3\n",
    "\n",
    "# Compute the Fast Fourier Transform (FFT)\n",
    "fft_result = np.fft.fft(composite_signal)\n",
    "fft_freq = np.fft.fftfreq(len(composite_signal), d=t[1]-t[0])\n",
    "\n",
    "# Compute the Power Spectral Density (PSD) using Welch's method\n",
    "f, Pxx = signal.welch(composite_signal, fs=1/(t[1]-t[0]), nperseg=256)\n",
    "\n",
    "# Compute the spectrogram\n",
    "f, t_spec, Sxx = signal.spectrogram(composite_signal, fs=1/(t[1]-t[0]), nperseg=64)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Time domain signal\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t, composite_signal, 'b-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('Time Domain Signal', fontsize=14)\n",
    "plt.xlabel('Time [s]', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "\n",
    "# FFT magnitude\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(fft_freq[:len(fft_freq)//2], np.abs(fft_result[:len(fft_result)//2]), 'r-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('Frequency Domain (FFT Magnitude)', fontsize=14)\n",
    "plt.xlabel('Frequency [Hz]', fontsize=12)\n",
    "plt.ylabel('Magnitude', fontsize=12)\n",
    "plt.xlim(0, 60)  # Limit to frequencies of interest\n",
    "\n",
    "# Power Spectral Density\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.semilogy(f, Pxx, 'g-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('Power Spectral Density (Welch\\'s Method)', fontsize=14)\n",
    "plt.xlabel('Frequency [Hz]', fontsize=12)\n",
    "plt.ylabel('PSD [V^2/Hz]', fontsize=12)\n",
    "plt.xlim(0, 60)  # Limit to frequencies of interest\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the spectrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pcolormesh(t_spec, f, 10 * np.log10(Sxx), shading='gouraud', cmap='viridis')\n",
    "plt.colorbar(label='Power/Frequency [dB/Hz]')\n",
    "plt.title('Spectrogram', fontsize=14)\n",
    "plt.xlabel('Time [s]', fontsize=12)\n",
    "plt.ylabel('Frequency [Hz]', fontsize=12)\n",
    "plt.ylim(0, 60)  # Limit to frequencies of interest\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 4.3 Image Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9147b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import ndimage\n",
    "from skimage import data, color\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a sample image\n",
    "astronaut = data.astronaut()\n",
    "astronaut_gray = color.rgb2gray(astronaut)\n",
    "\n",
    "# Apply various filters\n",
    "# Gaussian filter (blurring)\n",
    "gaussian_filtered = ndimage.gaussian_filter(astronaut_gray, sigma=3)\n",
    "\n",
    "# Sobel filter (edge detection)\n",
    "sobel_filtered = ndimage.sobel(astronaut_gray)\n",
    "\n",
    "# Median filter (noise reduction)\n",
    "median_filtered = ndimage.median_filter(astronaut_gray, size=5)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(astronaut_gray, cmap='gray')\n",
    "plt.title('Original Image (Grayscale)', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(gaussian_filtered, cmap='gray')\n",
    "plt.title('Gaussian Filter (Blurring)', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(sobel_filtered, cmap='gray')\n",
    "plt.title('Sobel Filter (Edge Detection)', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(median_filtered, cmap='gray')\n",
    "plt.title('Median Filter (Noise Reduction)', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Image rotation and zooming\n",
    "rotated_image = ndimage.rotate(astronaut_gray, angle=45, reshape=True)\n",
    "zoomed_image = ndimage.zoom(astronaut_gray, zoom=0.5)\n",
    "\n",
    "# Image morphology\n",
    "# Create a binary image\n",
    "binary_image = astronaut_gray > 0.5\n",
    "\n",
    "# Erosion and dilation\n",
    "eroded_image = ndimage.binary_erosion(binary_image)\n",
    "dilated_image = ndimage.binary_dilation(binary_image)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(rotated_image, cmap='gray')\n",
    "plt.title('Rotated Image (45 degrees)', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(zoomed_image, cmap='gray')\n",
    "plt.title('Zoomed Image (0.5x)', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(eroded_image, cmap='gray')\n",
    "plt.title('Eroded Binary Image', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(dilated_image, cmap='gray')\n",
    "plt.title('Dilated Binary Image', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ## 5. SciPy Statistics (`scipy.stats`)\n",
    "\n",
    "# ### 5.1 Probability Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define a range of x values\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "# Normal distribution\n",
    "mu, sigma = 0, 1\n",
    "normal_pdf = stats.norm.pdf(x, mu, sigma)\n",
    "normal_cdf = stats.norm.cdf(x, mu, sigma)\n",
    "\n",
    "# Student's t-distribution\n",
    "df = 3  # degrees of freedom\n",
    "t_pdf = stats.t.pdf(x, df)\n",
    "\n",
    "# Chi-squared distribution\n",
    "chi2_x = np.linspace(0, 10, 1000)\n",
    "chi2_pdf = stats.chi2.pdf(chi2_x, df)\n",
    "\n",
    "# F-distribution\n",
    "f_x = np.linspace(0, 5, 1000)\n",
    "dfn, dfd = 3, 10  # numerator and denominator degrees of freedom\n",
    "f_pdf = stats.f.pdf(f_x, dfn, dfd)\n",
    "\n",
    "# Plot the PDFs\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(x, normal_pdf, 'b-', linewidth=2, label=f'Normal(μ={mu}, σ={sigma})')\n",
    "plt.grid(True)\n",
    "plt.title('Normal Distribution PDF', fontsize=14)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('Probability Density', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(x, t_pdf, 'r-', linewidth=2, label=f't(df={df})')\n",
    "plt.plot(x, normal_pdf, 'b--', linewidth=1, label=f'Normal(μ={mu}, σ={sigma})')\n",
    "plt.grid(True)\n",
    "plt.title('Student\\'s t-Distribution PDF', fontsize=14)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('Probability Density', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(chi2_x, chi2_pdf, 'g-', linewidth=2, label=f'χ²(df={df})')\n",
    "plt.grid(True)\n",
    "plt.title('Chi-squared Distribution PDF', fontsize=14)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('Probability Density', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(f_x, f_pdf, 'm-', linewidth=2, label=f'F(dfn={dfn}, dfd={dfd})')\n",
    "plt.grid(True)\n",
    "plt.title('F-Distribution PDF', fontsize=14)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('Probability Density', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the normal CDF\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, normal_cdf, 'b-', linewidth=2, label=f'Normal(μ={mu}, σ={sigma}) CDF')\n",
    "plt.grid(True)\n",
    "plt.title('Normal Distribution CDF', fontsize=14)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('Cumulative Probability', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Generate random samples from distributions\n",
    "np.random.seed(42)\n",
    "normal_samples = stats.norm.rvs(mu, sigma, size=1000)\n",
    "t_samples = stats.t.rvs(df, size=1000)\n",
    "chi2_samples = stats.chi2.rvs(df, size=1000)\n",
    "f_samples = stats.f.rvs(dfn, dfd, size=1000)\n",
    "\n",
    "# Plot histograms of the samples\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(normal_samples, bins=30, density=True, alpha=0.7, color='blue')\n",
    "plt.plot(x, normal_pdf, 'r-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('Normal Distribution Samples', fontsize=14)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(t_samples, bins=30, density=True, alpha=0.7, color='red')\n",
    "plt.plot(x, t_pdf, 'b-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('Student\\'s t-Distribution Samples', fontsize=14)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(chi2_samples, bins=30, density=True, alpha=0.7, color='green')\n",
    "plt.plot(chi2_x, chi2_pdf, 'r-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('Chi-squared Distribution Samples', fontsize=14)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlim(0, 10)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(f_samples, bins=30, density=True, alpha=0.7, color='magenta')\n",
    "plt.plot(f_x, f_pdf, 'b-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.title('F-Distribution Samples', fontsize=14)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlim(0, 5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 5.2 Statistical Tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(42)\n",
    "group1 = stats.norm.rvs(loc=5, scale=1, size=100)\n",
    "group2 = stats.norm.rvs(loc=5.5, scale=1.2, size=100)\n",
    "\n",
    "# 1. t-test (comparing means)\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "print(\"Independent samples t-test:\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Conclusion: {'Reject' if p_value < 0.05 else 'Fail to reject'} null hypothesis at 5% significance level\\n\")\n",
    "\n",
    "# 2. F-test (comparing variances)\n",
    "f_stat = np.var(group1, ddof=1) / np.var(group2, ddof=1)\n",
    "dfn, dfd = len(group1) - 1, len(group2) - 1\n",
    "p_value = 2 * min(stats.f.cdf(f_stat, dfn, dfd), 1 - stats.f.cdf(f_stat, dfn, dfd))\n",
    "print(\"F-test for equal variances:\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Conclusion: {'Reject' if p_value < 0.05 else 'Fail to reject'} null hypothesis at 5% significance level\\n\")\n",
    "\n",
    "# 3. Shapiro-Wilk test (normality test)\n",
    "w_stat1, p_value1 = stats.shapiro(group1)\n",
    "w_stat2, p_value2 = stats.shapiro(group2)\n",
    "print(\"Shapiro-Wilk normality test:\")\n",
    "print(f\"Group 1: W-statistic: {w_stat1:.4f}, p-value: {p_value1:.4f}\")\n",
    "print(f\"Group 2: W-statistic: {w_stat2:.4f}, p-value: {p_value2:.4f}\")\n",
    "print(f\"Conclusion Group 1: {'Reject' if p_value1 < 0.05 else 'Fail to reject'} null hypothesis at 5% significance level\")\n",
    "print(f\"Conclusion Group 2: {'Reject' if p_value2 < 0.05 else 'Fail to reject'} null hypothesis at 5% significance level\\n\")\n",
    "\n",
    "# 4. Kolmogorov-Smirnov test (comparing distributions)\n",
    "ks_stat, p_value = stats.ks_2samp(group1, group2)\n",
    "print(\"Kolmogorov-Smirnov test:\")\n",
    "print(f\"KS-statistic: {ks_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Conclusion: {'Reject' if p_value < 0.05 else 'Fail to reject'} null hypothesis at 5% significance level\\n\")\n",
    "\n",
    "# 5. Chi-squared test (independence test)\n",
    "# Generate categorical data\n",
    "np.random.seed(42)\n",
    "observed = np.random.randint(1, 5, size=(4, 3))\n",
    "chi2_stat, p_value, dof, expected = stats.chi2_contingency(observed)\n",
    "print(\"Chi-squared test of independence:\")\n",
    "print(\"Observed frequencies:\")\n",
    "print(observed)\n",
    "print(\"Expected frequencies:\")\n",
    "print(expected)\n",
    "print(f\"Chi-squared statistic: {chi2_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"Conclusion: {'Reject' if p_value < 0.05 else 'Fail to reject'} null hypothesis at 5% significance level\\n\")\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Histogram comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(group1, bins=20, alpha=0.5, label='Group 1')\n",
    "plt.hist(group2, bins=20, alpha=0.5, label='Group 2')\n",
    "plt.grid(True)\n",
    "plt.title('Histogram Comparison', fontsize=14)\n",
    "plt.xlabel('Value', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "# Box plot comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.boxplot([group1, group2], labels=['Group 1', 'Group 2'])\n",
    "plt.grid(True)\n",
    "plt.title('Box Plot Comparison', fontsize=14)\n",
    "plt.ylabel('Value', fontsize=12)\n",
    "\n",
    "# Q-Q plot for normality check\n",
    "plt.subplot(2, 2, 3)\n",
    "stats.probplot(group1, plot=plt)\n",
    "plt.grid(True)\n",
    "plt.title('Q-Q Plot (Group 1)', fontsize=14)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "stats.probplot(group2, plot=plt)\n",
    "plt.grid(True)\n",
    "plt.title('Q-Q Plot (Group 2)', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 5.3 Regression and Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate some correlated data\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = 2 * x + 1 + np.random.normal(0, 2, size=len(x))\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"Slope: {slope:.4f}\")\n",
    "print(f\"Intercept: {intercept:.4f}\")\n",
    "print(f\"R-squared: {r_value**2:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Standard Error: {std_err:.4f}\")\n",
    "\n",
    "# Correlation coefficients\n",
    "pearson_r, pearson_p = stats.pearsonr(x, y)\n",
    "spearman_r, spearman_p = stats.spearmanr(x, y)\n",
    "kendall_tau, kendall_p = stats.kendalltau(x, y)\n",
    "\n",
    "print(\"\\nCorrelation Coefficients:\")\n",
    "print(f\"Pearson's r: {pearson_r:.4f} (p-value: {pearson_p:.4f})\")\n",
    "print(f\"Spearman's rho: {spearman_r:.4f} (p-value: {spearman_p:.4f})\")\n",
    "print(f\"Kendall's tau: {kendall_tau:.4f} (p-value: {kendall_p:.4f})\")\n",
    "\n",
    "# Plot the data and regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, alpha=0.7, label='Data points')\n",
    "plt.plot(x, intercept + slope * x, 'r-', linewidth=2, label=f'Regression line: y = {slope:.2f}x + {intercept:.2f}')\n",
    "plt.grid(True)\n",
    "plt.title('Linear Regression', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.legend()\n",
    "plt.text(1, 18, f'R² = {r_value**2:.4f}', fontsize=14, bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.show()\n",
    "\n",
    "# Generate non-linear data for comparison\n",
    "np.random.seed(42)\n",
    "x_nl = np.linspace(0, 10, 100)\n",
    "y_nl = 2 * np.sin(x_nl) + np.random.normal(0, 0.5, size=len(x_nl))\n",
    "\n",
    "# Calculate correlation coefficients\n",
    "pearson_r_nl, pearson_p_nl = stats.pearsonr(x_nl, y_nl)\n",
    "spearman_r_nl, spearman_p_nl = stats.spearmanr(x_nl, y_nl)\n",
    "kendall_tau_nl, kendall_p_nl = stats.kendalltau(x_nl, y_nl)\n",
    "\n",
    "print(\"\\nNon-linear Data Correlation Coefficients:\")\n",
    "print(f\"Pearson's r: {pearson_r_nl:.4f} (p-value: {pearson_p_nl:.4f})\")\n",
    "print(f\"Spearman's rho: {spearman_r_nl:.4f} (p-value: {spearman_p_nl:.4f})\")\n",
    "print(f\"Kendall's tau: {kendall_tau_nl:.4f} (p-value: {kendall_p_nl:.4f})\")\n",
    "\n",
    "# Plot the non-linear data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_nl, y_nl, alpha=0.7, label='Data points')\n",
    "plt.grid(True)\n",
    "plt.title('Non-linear Relationship', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.text(1, 2.5, f'Pearson\\'s r = {pearson_r_nl:.4f}\\nSpearman\\'s rho = {spearman_r_nl:.4f}', \n",
    "         fontsize=14, bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 5.4 Kernel Density Estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a mixture of two normal distributions\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "sample1 = np.random.normal(0, 1, size=int(0.7 * n_samples))\n",
    "sample2 = np.random.normal(5, 1, size=int(0.3 * n_samples))\n",
    "samples = np.concatenate([sample1, sample2])\n",
    "\n",
    "# Compute kernel density estimate\n",
    "x_grid = np.linspace(-4, 9, 1000)\n",
    "kde = stats.gaussian_kde(samples)\n",
    "pdf = kde(x_grid)\n",
    "\n",
    "# Compute histogram\n",
    "hist, bin_edges = np.histogram(samples, bins=30, density=True)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Histogram and KDE\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(samples, bins=30, density=True, alpha=0.5, label='Histogram')\n",
    "plt.plot(x_grid, pdf, 'r-', linewidth=2, label='KDE')\n",
    "plt.grid(True)\n",
    "plt.title('Kernel Density Estimation', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "# Compare different bandwidths\n",
    "plt.subplot(2, 1, 2)\n",
    "bandwidths = [0.1, 0.5, 1.0, 2.0]\n",
    "for bw in bandwidths:\n",
    "    kde = stats.gaussian_kde(samples, bw_method=bw)\n",
    "    pdf = kde(x_grid)\n",
    "    plt.plot(x_grid, pdf, linewidth=2, label=f'Bandwidth = {bw}')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title('KDE with Different Bandwidths', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2D Kernel Density Estimation\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "mean1 = [0, 0]\n",
    "cov1 = [[1, 0.5], [0.5, 1]]\n",
    "mean2 = [4, 4]\n",
    "cov2 = [[1, -0.5], [-0.5, 1]]\n",
    "\n",
    "sample1 = np.random.multivariate_normal(mean1, cov1, size=int(0.6 * n_samples))\n",
    "sample2 = np.random.multivariate_normal(mean2, cov2, size=int(0.4 * n_samples))\n",
    "samples = np.vstack([sample1, sample2])\n",
    "\n",
    "# Compute 2D KDE\n",
    "x_grid = np.linspace(-3, 7, 100)\n",
    "y_grid = np.linspace(-3, 7, 100)\n",
    "X, Y = np.meshgrid(x_grid, y_grid)\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "kernel = stats.gaussian_kde(samples.T)\n",
    "Z = np.reshape(kernel(positions), X.shape)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Scatter plot\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(samples[:, 0], samples[:, 1], alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.title('Scatter Plot of 2D Data', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "\n",
    "# 2D KDE\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.contourf(X, Y, Z, cmap='viridis')\n",
    "plt.colorbar(label='Density')\n",
    "plt.scatter(samples[:, 0], samples[:, 1], alpha=0.1, color='white')\n",
    "plt.grid(True)\n",
    "plt.title('2D Kernel Density Estimation', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ## 6. Real-world Applications of SciPy in Machine Learning\n",
    "\n",
    "# ### 6.1 Principal Component Analysis (PCA) Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Standardize the data\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Compute the covariance matrix\n",
    "cov_matrix = np.cov(X_std.T)\n",
    "print(\"Covariance Matrix:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort eigenvalues and eigenvectors in descending order\n",
    "idx = eigenvalues.argsort()[::-1]\n",
    "eigenvalues = eigenvalues[idx].real\n",
    "eigenvectors = eigenvectors[:, idx].real\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Compute explained variance ratio\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "# Cumulative explained variance\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "print(\"\\nCumulative Explained Variance Ratio:\")\n",
    "print(cumulative_variance_ratio)\n",
    "\n",
    "# Project the data onto the principal components\n",
    "X_pca = X_std @ eigenvectors\n",
    "\n",
    "# Plot the explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(eigenvalues) + 1), eigenvalues, alpha=0.7, label='Individual explained variance')\n",
    "plt.step(range(1, len(eigenvalues) + 1), cumulative_variance_ratio, where='mid', label='Cumulative explained variance')\n",
    "plt.grid(True)\n",
    "plt.title('Explained Variance by Principal Components', fontsize=16)\n",
    "plt.xlabel('Principal Component', fontsize=14)\n",
    "plt.ylabel('Explained Variance Ratio', fontsize=14)\n",
    "plt.xticks(range(1, len(eigenvalues) + 1))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the first two principal components\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, alpha=0.7, lw=1, label=target_name)\n",
    "plt.grid(True)\n",
    "plt.title('PCA of Iris Dataset', fontsize=16)\n",
    "plt.xlabel('First Principal Component', fontsize=14)\n",
    "plt.ylabel('Second Principal Component', fontsize=14)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the loadings (feature contributions to principal components)\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(len(feature_names)):\n",
    "    plt.arrow(0, 0, eigenvectors[i, 0], eigenvectors[i, 1], color='r', alpha=0.7, head_width=0.05, head_length=0.05)\n",
    "    plt.text(eigenvectors[i, 0] * 1.15, eigenvectors[i, 1] * 1.15, feature_names[i], color='g', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel('PC1', fontsize=14)\n",
    "plt.ylabel('PC2', fontsize=14)\n",
    "plt.title('Feature Loadings', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 6.2 Clustering with Gaussian Mixture Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cef510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 300\n",
    "X, y_true = make_blobs(n_samples=n_samples, centers=3, cluster_std=[1.0, 1.5, 0.5], random_state=42)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, alpha=0.7)\n",
    "plt.grid(True)\n",
    "plt.title('Generated Data', fontsize=16)\n",
    "plt.xlabel('Feature 1', fontsize=14)\n",
    "plt.ylabel('Feature 2', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Implement Expectation-Maximization (EM) algorithm for Gaussian Mixture Models\n",
    "def gmm_em(X, n_components, max_iter=100, tol=1e-4):\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialize parameters\n",
    "    weights = np.ones(n_components) / n_components\n",
    "    means = X[np.random.choice(n_samples, n_components, replace=False)]\n",
    "    covariances = [np.eye(n_features) for _ in range(n_components)]\n",
    "    \n",
    "    # Initialize log-likelihood\n",
    "    log_likelihood = 0\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        # E-step: Compute responsibilities\n",
    "        responsibilities = np.zeros((n_samples, n_components))\n",
    "        for k in range(n_components):\n",
    "            responsibilities[:, k] = weights[k] * multivariate_normal.pdf(X, mean=means[k], cov=covariances[k])\n",
    "        \n",
    "        # Normalize responsibilities\n",
    "        responsibilities_sum = responsibilities.sum(axis=1, keepdims=True)\n",
    "        responsibilities /= responsibilities_sum\n",
    "        \n",
    "        # M-step: Update parameters\n",
    "        N_k = responsibilities.sum(axis=0)\n",
    "        \n",
    "        # Update weights\n",
    "        weights = N_k / n_samples\n",
    "        \n",
    "        # Update means\n",
    "        means = np.dot(responsibilities.T, X) / N_k[:, np.newaxis]\n",
    "        \n",
    "        # Update covariances\n",
    "        for k in range(n_components):\n",
    "            diff = X - means[k]\n",
    "            covariances[k] = np.dot(responsibilities[:, k] * diff.T, diff) / N_k[k]\n",
    "            \n",
    "            # Add a small regularization term to ensure positive definiteness\n",
    "            covariances[k] += 1e-6 * np.eye(n_features)\n",
    "        \n",
    "        # Compute log-likelihood\n",
    "        new_log_likelihood = 0\n",
    "        for i in range(n_samples):\n",
    "            likelihood = 0\n",
    "            for k in range(n_components):\n",
    "                likelihood += weights[k] * multivariate_normal.pdf(X[i], mean=means[k], cov=covariances[k])\n",
    "            new_log_likelihood += np.log(likelihood)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if abs(new_log_likelihood - log_likelihood) < tol:\n",
    "            break\n",
    "        \n",
    "        log_likelihood = new_log_likelihood\n",
    "    \n",
    "    # Assign cluster labels\n",
    "    cluster_labels = np.argmax(responsibilities, axis=1)\n",
    "    \n",
    "    return weights, means, covariances, cluster_labels, responsibilities\n",
    "\n",
    "# Fit GMM to the data\n",
    "n_components = 3\n",
    "weights, means, covariances, cluster_labels, responsibilities = gmm_em(X, n_components)\n",
    "\n",
    "# Plot the clustering results\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot the data points with cluster assignments\n",
    "plt.subplot(2, 1, 1)\n",
    "colors = ['blue', 'green', 'red']\n",
    "for k in range(n_components):\n",
    "    plt.scatter(X[cluster_labels == k, 0], X[cluster_labels == k, 1], \n",
    "                s=50, alpha=0.7, color=colors[k], label=f'Cluster {k+1}')\n",
    "plt.grid(True)\n",
    "plt.title('GMM Clustering Results', fontsize=16)\n",
    "plt.xlabel('Feature 1', fontsize=14)\n",
    "plt.ylabel('Feature 2', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "# Plot the Gaussian components\n",
    "plt.subplot(2, 1, 2)\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "Z = np.zeros((100, 100))\n",
    "\n",
    "for k in range(n_components):\n",
    "    Z_k = multivariate_normal.pdf(np.c_[xx.ravel(), yy.ravel()], mean=means[k], cov=covariances[k])\n",
    "    Z_k = Z_k.reshape(xx.shape) * weights[k]\n",
    "    Z += Z_k\n",
    "    plt.contour(xx, yy, Z_k, levels=5, colors=colors[k], alpha=0.5)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], s=30, alpha=0.3, c='gray')\n",
    "plt.grid(True)\n",
    "plt.title('Gaussian Components', fontsize=16)\n",
    "plt.xlabel('Feature 1', fontsize=14)\n",
    "plt.ylabel('Feature 2', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the responsibilities (soft assignments)\n",
    "plt.figure(figsize=(15, 5))\n",
    "for k in range(n_components):\n",
    "    plt.subplot(1, 3, k+1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=responsibilities[:, k], cmap='viridis', s=50, alpha=0.7)\n",
    "    plt.colorbar(label='Responsibility')\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Cluster {k+1} Responsibilities', fontsize=14)\n",
    "    plt.xlabel('Feature 1', fontsize=12)\n",
    "    plt.ylabel('Feature 2', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 6.3 Signal Processing for Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Generate synthetic time series data for classification\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "time_points = 500\n",
    "t = np.linspace(0, 10, time_points)\n",
    "\n",
    "# Class 1: Signal with low frequency components\n",
    "class1_data = []\n",
    "for _ in range(n_samples):\n",
    "    # Base signal: sum of sine waves with low frequencies\n",
    "    base_signal = np.sin(2 * np.pi * 0.5 * t) + 0.5 * np.sin(2 * np.pi * 1.0 * t)\n",
    "    # Add noise\n",
    "    noise = 0.5 * np.random.normal(size=len(t))\n",
    "    signal_with_noise = base_signal + noise\n",
    "    class1_data.append(signal_with_noise)\n",
    "\n",
    "# Class 2: Signal with high frequency components\n",
    "class2_data = []\n",
    "for _ in range(n_samples):\n",
    "    # Base signal: sum of sine waves with high frequencies\n",
    "    base_signal = np.sin(2 * np.pi * 2.0 * t) + 0.5 * np.sin(2 * np.pi * 3.0 * t)\n",
    "    # Add noise\n",
    "    noise = 0.5 * np.random.normal(size=len(t))\n",
    "    signal_with_noise = base_signal + noise\n",
    "    class2_data.append(signal_with_noise)\n",
    "\n",
    "# Combine data and create labels\n",
    "X_raw = np.vstack([class1_data, class2_data])\n",
    "y = np.hstack([np.zeros(n_samples), np.ones(n_samples)])\n",
    "\n",
    "# Plot example signals from each class\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, X_raw[0], 'b-', linewidth=1, alpha=0.7, label='Sample from Class 0')\n",
    "plt.grid(True)\n",
    "plt.title('Example Signal from Class 0 (Low Frequency)', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t, X_raw[n_samples], 'r-', linewidth=1, alpha=0.7, label='Sample from Class 1')\n",
    "plt.grid(True)\n",
    "plt.title('Example Signal from Class 1 (High Frequency)', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature extraction using Fourier Transform\n",
    "def extract_fft_features(signals, n_features=20):\n",
    "    features = []\n",
    "    for signal in signals:\n",
    "        # Compute FFT\n",
    "        fft_result = np.fft.fft(signal)\n",
    "        # Take the magnitude of the first n_features frequencies\n",
    "        fft_features = np.abs(fft_result[:n_features])\n",
    "        features.append(fft_features)\n",
    "    return np.array(features)\n",
    "\n",
    "# Feature extraction using Power Spectral Density\n",
    "def extract_psd_features(signals, fs=50, n_features=20):\n",
    "    features = []\n",
    "    for signal in signals:\n",
    "        # Compute PSD using Welch's method\n",
    "        f, Pxx = signal.welch(signal, fs=fs, nperseg=256)\n",
    "        # Take the first n_features PSD values\n",
    "        psd_features = Pxx[:n_features]\n",
    "        features.append(psd_features)\n",
    "    return np.array(features)\n",
    "\n",
    "# Feature extraction using Wavelet Transform\n",
    "def extract_wavelet_features(signals, n_features=20):\n",
    "    features = []\n",
    "    for signal in signals:\n",
    "        # Compute Continuous Wavelet Transform\n",
    "        widths = np.arange(1, n_features + 1)\n",
    "        cwtmatr = signal.cwt(signal, signal.ricker, widths)\n",
    "        # Take the mean and std of each wavelet scale as features\n",
    "        wavelet_features = np.hstack([cwtmatr.mean(axis=1), cwtmatr.std(axis=1)])\n",
    "        features.append(wavelet_features)\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features\n",
    "X_fft = extract_fft_features(X_raw)\n",
    "X_psd = extract_psd_features(X_raw)\n",
    "X_wavelet = extract_wavelet_features(X_raw)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_fft_train, X_fft_test, y_train, y_test = train_test_split(X_fft, y, test_size=0.3, random_state=42)\n",
    "X_psd_train, X_psd_test, _, _ = train_test_split(X_psd, y, test_size=0.3, random_state=42)\n",
    "X_wavelet_train, X_wavelet_test, _, _ = train_test_split(X_wavelet, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train classifiers\n",
    "clf_fft = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_fft.fit(X_fft_train, y_train)\n",
    "y_pred_fft = clf_fft.predict(X_fft_test)\n",
    "\n",
    "clf_psd = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_psd.fit(X_psd_train, y_train)\n",
    "y_pred_psd = clf_psd.predict(X_psd_test)\n",
    "\n",
    "clf_wavelet = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_wavelet.fit(X_wavelet_train, y_train)\n",
    "y_pred_wavelet = clf_wavelet.predict(X_wavelet_test)\n",
    "\n",
    "# Evaluate classifiers\n",
    "print(\"FFT Features Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_fft))\n",
    "print(\"\\nPSD Features Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_psd))\n",
    "print(\"\\nWavelet Features Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_wavelet))\n",
    "\n",
    "# Plot feature importance for FFT features\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.bar(range(X_fft.shape[1]), clf_fft.feature_importances_)\n",
    "plt.grid(True)\n",
    "plt.title('FFT Feature Importance', fontsize=14)\n",
    "plt.xlabel('Feature Index', fontsize=12)\n",
    "plt.ylabel('Importance', fontsize=12)\n",
    "\n",
    "# Plot feature importance for PSD features\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.bar(range(X_psd.shape[1]), clf_psd.feature_importances_)\n",
    "plt.grid(True)\n",
    "plt.title('PSD Feature Importance', fontsize=14)\n",
    "plt.xlabel('Feature Index', fontsize=12)\n",
    "plt.ylabel('Importance', fontsize=12)\n",
    "\n",
    "# Plot feature importance for Wavelet features\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.bar(range(X_wavelet.shape[1]), clf_wavelet.feature_importances_)\n",
    "plt.grid(True)\n",
    "plt.title('Wavelet Feature Importance', fontsize=14)\n",
    "plt.xlabel('Feature Index', fontsize=12)\n",
    "plt.ylabel('Importance', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the features\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# FFT features\n",
    "plt.subplot(3, 1, 1)\n",
    "for i in range(10):  # Plot first 10 samples from each class\n",
    "    plt.plot(X_fft[i], 'b-', alpha=0.3)\n",
    "    plt.plot(X_fft[n_samples + i], 'r-', alpha=0.3)\n",
    "plt.grid(True)\n",
    "plt.title('FFT Features', fontsize=14)\n",
    "plt.xlabel('Feature Index', fontsize=12)\n",
    "plt.ylabel('Magnitude', fontsize=12)\n",
    "\n",
    "# PSD features\n",
    "plt.subplot(3, 1, 2)\n",
    "for i in range(10):  # Plot first 10 samples from each class\n",
    "    plt.plot(X_psd[i], 'b-', alpha=0.3)\n",
    "    plt.plot(X_psd[n_samples + i], 'r-', alpha=0.3)\n",
    "plt.grid(True)\n",
    "plt.title('PSD Features', fontsize=14)\n",
    "plt.xlabel('Feature Index', fontsize=12)\n",
    "plt.ylabel('Power', fontsize=12)\n",
    "\n",
    "# Wavelet features\n",
    "plt.subplot(3, 1, 3)\n",
    "for i in range(10):  # Plot first 10 samples from each class\n",
    "    plt.plot(X_wavelet[i], 'b-', alpha=0.3)\n",
    "    plt.plot(X_wavelet[n_samples + i], 'r-', alpha=0.3)\n",
    "plt.grid(True)\n",
    "plt.title('Wavelet Features', fontsize=14)\n",
    "plt.xlabel('Feature Index', fontsize=12)\n",
    "plt.ylabel('Value', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### 6.4 Optimization for Machine Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f17de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy import optimize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Generate synthetic regression data\n",
    "np.random.seed(42)\n",
    "X, y, coef = make_regression(n_samples=100, n_features=3, n_informative=3, noise=10, coef=True, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression using SciPy's optimization\n",
    "def linear_regression_cost(params, X, y):\n",
    "    \"\"\"Cost function for linear regression (Mean Squared Error)\"\"\"\n",
    "    y_pred = X @ params\n",
    "    return np.mean((y_pred - y) ** 2)\n",
    "\n",
    "def linear_regression_gradient(params, X, y):\n",
    "    \"\"\"Gradient of the cost function\"\"\"\n",
    "    y_pred = X @ params\n",
    "    return 2 * X.T @ (y_pred - y) / len(y)\n",
    "\n",
    "# Initialize parameters\n",
    "initial_params = np.zeros(X_train.shape[1])\n",
    "\n",
    "# Optimize using different methods\n",
    "methods = ['BFGS', 'CG', 'Newton-CG', 'L-BFGS-B']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    # Optimize\n",
    "    result = optimize.minimize(\n",
    "        linear_regression_cost, \n",
    "        initial_params, \n",
    "        args=(X_train, y_train), \n",
    "        method=method, \n",
    "        jac=linear_regression_gradient,\n",
    "        options={'maxiter': 1000}\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    results[method] = {\n",
    "        'params': result.x,\n",
    "        'success': result.success,\n",
    "        'iterations': result.nit,\n",
    "        'function_evaluations': result.nfev,\n",
    "        'message': result.message\n",
    "    }\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = X_train @ result.x\n",
    "    y_pred_test = X_test @ result.x\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    results[method].update({\n",
    "        'train_mse': train_mse,\n",
    "        'test_mse': test_mse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(\"True coefficients:\", coef)\n",
    "print(\"\\nOptimization Results:\")\n",
    "for method, result in results.items():\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(f\"Estimated coefficients: {result['params']}\")\n",
    "    print(f\"Training MSE: {result['train_mse']:.4f}\")\n",
    "    print(f\"Testing MSE: {result['test_mse']:.4f}\")\n",
    "    print(f\"Training R²: {result['train_r2']:.4f}\")\n",
    "    print(f\"Testing R²: {result['test_r2']:.4f}\")\n",
    "    print(f\"Iterations: {result['iterations']}\")\n",
    "    print(f\"Function evaluations: {result['function_evaluations']}\")\n",
    "    print(f\"Success: {result['success']}\")\n",
    "    print(f\"Message: {result['message']}\")\n",
    "\n",
    "# Logistic Regression using SciPy's optimization\n",
    "# Generate synthetic classification data\n",
    "np.random.seed(42)\n",
    "X, y = make_regression(n_samples=100, n_features=2, n_informative=2, noise=10, random_state=42)\n",
    "y = (y > 0).astype(int)  # Convert to binary classification\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid function\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression_cost(params, X, y):\n",
    "    \"\"\"Cost function for logistic regression (Binary Cross-Entropy)\"\"\"\n",
    "    z = X @ params\n",
    "    h = sigmoid(z)\n",
    "    cost = -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h + 1e-10))\n",
    "    return cost\n",
    "\n",
    "def logistic_regression_gradient(params, X, y):\n",
    "    \"\"\"Gradient of the cost function\"\"\"\n",
    "    z = X @ params\n",
    "    h = sigmoid(z)\n",
    "    return X.T @ (h - y) / len(y)\n",
    "\n",
    "# Initialize parameters\n",
    "initial_params = np.zeros(X_train.shape[1])\n",
    "\n",
    "# Optimize\n",
    "result = optimize.minimize(\n",
    "    logistic_regression_cost, \n",
    "    initial_params, \n",
    "    args=(X_train, y_train), \n",
    "    method='BFGS', \n",
    "    jac=logistic_regression_gradient,\n",
    "    options={'maxiter': 1000}\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "z_train = X_train @ result.x\n",
    "z_test = X_test @ result.x\n",
    "y_pred_train_prob = sigmoid(z_train)\n",
    "y_pred_test_prob = sigmoid(z_test)\n",
    "y_pred_train = (y_pred_train_prob >= 0.5).astype(int)\n",
    "y_pred_test = (y_pred_test_prob >= 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = np.mean(y_pred_train == y_train)\n",
    "test_accuracy = np.mean(y_pred_test == y_test)\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(f\"Estimated coefficients: {result.x}\")\n",
    "print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Iterations: {result.nit}\")\n",
    "print(f\"Function evaluations: {result.nfev}\")\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Message: {result.message}\")\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure(figsize=(10, 8))\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "Z = sigmoid(np.c_[xx.ravel(), yy.ravel()] @ result.x)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "plt.colorbar(label='Probability')\n",
    "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], c='blue', marker='o', alpha=0.7, label='Class 0 (Train)')\n",
    "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], c='red', marker='o', alpha=0.7, label='Class 1 (Train)')\n",
    "plt.scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1], c='blue', marker='^', alpha=0.7, label='Class 0 (Test)')\n",
    "plt.scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], c='red', marker='^', alpha=0.7, label='Class 1 (Test)')\n",
    "plt.contour(xx, yy, Z, levels=[0.5], colors='k', linestyles='--', linewidths=2)\n",
    "plt.grid(True)\n",
    "plt.title('Logistic Regression Decision Boundary', fontsize=16)\n",
    "plt.xlabel('Feature 1', fontsize=14)\n",
    "plt.ylabel('Feature 2', fontsize=14)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ## 7. Test Your Knowledge\n",
    "\n",
    "# ### Exercise 1: Optimization\n",
    "# \n",
    "# 1. Define a function f(x, y) = x^2 + y^2 - 2x - 4y + 5\n",
    "# 2. Find the minimum of this function using SciPy's optimization tools\n",
    "# 3. Verify your answer by computing the gradient at the minimum\n",
    "# 4. Plot the function and mark the minimum point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Your code here\n",
    "# Example solution:\n",
    "from scipy import optimize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define the function\n",
    "def f(params):\n",
    "    x, y = params\n",
    "    return x**2 + y**2 - 2*x - 4*y + 5\n",
    "\n",
    "# Define the gradient (optional, but can speed up optimization)\n",
    "def gradient(params):\n",
    "    x, y = params\n",
    "    return np.array([2*x - 2, 2*y - 4])\n",
    "\n",
    "# 2. Find the minimum\n",
    "initial_guess = [0, 0]\n",
    "result = optimize.minimize(f, initial_guess, method='BFGS', jac=gradient)\n",
    "\n",
    "print(\"Optimization Result:\")\n",
    "print(f\"Minimum at x = {result.x[0]:.4f}, y = {result.x[1]:.4f}\")\n",
    "print(f\"Minimum value: f(x,y) = {result.fun:.4f}\")\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Message: {result.message}\")\n",
    "\n",
    "# 3. Verify by computing the gradient at the minimum\n",
    "grad_at_min = gradient(result.x)\n",
    "print(\"\\nGradient at minimum:\")\n",
    "print(f\"∇f(x,y) = [{grad_at_min[0]:.10f}, {grad_at_min[1]:.10f}]\")\n",
    "print(\"The gradient should be close to zero at the minimum.\")\n",
    "\n",
    "# 4. Plot the function and mark the minimum point\n",
    "x = np.linspace(-1, 3, 100)\n",
    "y = np.linspace(-1, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = X**2 + Y**2 - 2*X - 4*Y + 5\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "contour = plt.contourf(X, Y, Z, 50, cmap='viridis')\n",
    "plt.colorbar(label='f(x,y)')\n",
    "plt.contour(X, Y, Z, 20, colors='k', linewidths=0.5, alpha=0.3)\n",
    "plt.scatter(result.x[0], result.x[1], color='red', s=100, marker='*', label=f'Minimum: ({result.x[0]:.2f}, {result.x[1]:.2f})')\n",
    "plt.grid(True)\n",
    "plt.title('Function: f(x,y) = x² + y² - 2x - 4y + 5', fontsize=16)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### Exercise 2: Signal Processing\n",
    "# \n",
    "# 1. Generate a signal that is a sum of two sine waves with frequencies 5 Hz and 20 Hz\n",
    "# 2. Add random noise to the signal\n",
    "# 3. Apply a low-pass filter to remove the high-frequency component\n",
    "# 4. Plot the original signal, noisy signal, and filtered signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Your code here\n",
    "# Example solution:\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Generate a signal with two frequency components\n",
    "np.random.seed(42)\n",
    "t = np.linspace(0, 1, 1000, endpoint=False)\n",
    "f1, f2 = 5, 20  # frequencies in Hz\n",
    "signal_clean = np.sin(2 * np.pi * f1 * t) + 0.5 * np.sin(2 * np.pi * f2 * t)\n",
    "\n",
    "# 2. Add random noise\n",
    "noise = 0.5 * np.random.normal(size=len(t))\n",
    "signal_noisy = signal_clean + noise\n",
    "\n",
    "# 3. Apply a low-pass filter to remove the high-frequency component\n",
    "# Design a Butterworth low-pass filter\n",
    "cutoff = 10  # cutoff frequency in Hz\n",
    "fs = 1 / (t[1] - t[0])  # sampling frequency\n",
    "nyquist = 0.5 * fs\n",
    "normal_cutoff = cutoff / nyquist\n",
    "b, a = signal.butter(4, normal_cutoff, 'low', analog=False)\n",
    "\n",
    "# Apply the filter\n",
    "signal_filtered = signal.filtfilt(b, a, signal_noisy)\n",
    "\n",
    "# 4. Plot the signals\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Time domain plots\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t, signal_clean, 'g-', linewidth=2, label='Clean signal')\n",
    "plt.grid(True)\n",
    "plt.title('Original Clean Signal', fontsize=14)\n",
    "plt.xlabel('Time [s]', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(t, signal_noisy, 'b-', linewidth=1, label='Noisy signal')\n",
    "plt.grid(True)\n",
    "plt.title('Noisy Signal', fontsize=14)\n",
    "plt.xlabel('Time [s]', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(t, signal_filtered, 'r-', linewidth=2, label='Filtered signal')\n",
    "plt.grid(True)\n",
    "plt.title(f'Filtered Signal (Low-pass, cutoff={cutoff} Hz)', fontsize=14)\n",
    "plt.xlabel('Time [s]', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Frequency domain analysis\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Compute FFT\n",
    "fft_clean = np.fft.fft(signal_clean)\n",
    "fft_noisy = np.fft.fft(signal_noisy)\n",
    "fft_filtered = np.fft.fft(signal_filtered)\n",
    "freq = np.fft.fftfreq(len(t), d=t[1]-t[0])\n",
    "\n",
    "# Plot only the positive frequencies up to Nyquist frequency\n",
    "positive_freq_idx = np.where(freq > 0)[0]\n",
    "max_idx = np.where(freq <= nyquist)[0][-1]\n",
    "plot_idx = np.intersect1d(positive_freq_idx, np.arange(0, max_idx+1))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(freq[plot_idx], np.abs(fft_clean[plot_idx]), 'g-', linewidth=2, label='Clean signal')\n",
    "plt.grid(True)\n",
    "plt.title('Frequency Spectrum - Clean Signal', fontsize=14)\n",
    "plt.xlabel('Frequency [Hz]', fontsize=12)\n",
    "plt.ylabel('Magnitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(freq[plot_idx], np.abs(fft_noisy[plot_idx]), 'b-', linewidth=2, label='Noisy signal')\n",
    "plt.grid(True)\n",
    "plt.title('Frequency Spectrum - Noisy Signal', fontsize=14)\n",
    "plt.xlabel('Frequency [Hz]', fontsize=12)\n",
    "plt.ylabel('Magnitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(freq[plot_idx], np.abs(fft_filtered[plot_idx]), 'r-', linewidth=2, label='Filtered signal')\n",
    "plt.axvline(x=cutoff, color='k', linestyle='--', label=f'Cutoff ({cutoff} Hz)')\n",
    "plt.grid(True)\n",
    "plt.title('Frequency Spectrum - Filtered Signal', fontsize=14)\n",
    "plt.xlabel('Frequency [Hz]', fontsize=12)\n",
    "plt.ylabel('Magnitude', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### Exercise 3: Linear Algebra\n",
    "# \n",
    "# 1. Create a 3x3 matrix A with random values\n",
    "# 2. Compute its eigenvalues and eigenvectors\n",
    "# 3. Verify that Av = λv for each eigenpair\n",
    "# 4. Reconstruct the matrix using the eigendecomposition: A = PDP^(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc47db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Your code here\n",
    "# Example solution:\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create a random 3x3 matrix\n",
    "np.random.seed(42)\n",
    "A = np.random.rand(3, 3)\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "\n",
    "# 2. Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = linalg.eig(A)\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(\"\\nEigenvectors (by column):\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# 3. Verify Av = λv for each eigenpair\n",
    "print(\"\\nVerification of Av = λv:\")\n",
    "for i in range(3):\n",
    "    v = eigenvectors[:, i]\n",
    "    lambda_i = eigenvalues[i]\n",
    "    Av = A @ v\n",
    "    lambda_v = lambda_i * v\n",
    "    print(f\"\\nEigenpair {i+1}:\")\n",
    "    print(f\"λ = {lambda_i:.6f}\")\n",
    "    print(f\"v = {v}\")\n",
    "    print(f\"Av = {Av}\")\n",
    "    print(f\"λv = {lambda_v}\")\n",
    "    print(f\"||Av - λv|| = {np.linalg.norm(Av - lambda_v):.10f}\")\n",
    "\n",
    "# 4. Reconstruct the matrix using eigendecomposition\n",
    "# A = PDP^(-1) where P is the matrix of eigenvectors and D is the diagonal matrix of eigenvalues\n",
    "P = eigenvectors\n",
    "D = np.diag(eigenvalues)\n",
    "P_inv = linalg.inv(P)\n",
    "\n",
    "A_reconstructed = P @ D @ P_inv\n",
    "\n",
    "print(\"\\nReconstructed matrix A = PDP^(-1):\")\n",
    "print(A_reconstructed)\n",
    "\n",
    "print(\"\\nOriginal matrix A:\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\nDifference ||A - A_reconstructed||:\")\n",
    "print(np.linalg.norm(A - A_reconstructed))\n",
    "\n",
    "\n",
    "# ### Exercise 4: Statistics\n",
    "# \n",
    "# 1. Generate two samples from different normal distributions\n",
    "# 2. Perform a t-test to determine if their means are significantly different\n",
    "# 3. Create a Q-Q plot to check if the samples follow a normal distribution\n",
    "# 4. Compute and plot the kernel density estimation for both samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Your code here\n",
    "# Example solution:\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Generate two samples from different normal distributions\n",
    "np.random.seed(42)\n",
    "sample1 = stats.norm.rvs(loc=5, scale=1.5, size=100)\n",
    "sample2 = stats.norm.rvs(loc=6, scale=2, size=100)\n",
    "\n",
    "# 2. Perform a t-test\n",
    "t_stat, p_value = stats.ttest_ind(sample1, sample2)\n",
    "\n",
    "print(\"Independent samples t-test:\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Conclusion: {'Reject' if p_value < 0.05 else 'Fail to reject'} null hypothesis at 5% significance level\")\n",
    "\n",
    "# 3. Create Q-Q plots\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "stats.probplot(sample1, plot=plt)\n",
    "plt.grid(True)\n",
    "plt.title('Q-Q Plot for Sample 1', fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(sample2, plot=plt)\n",
    "plt.grid(True)\n",
    "plt.title('Q-Q Plot for Sample 2', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Compute and plot kernel density estimation\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Histogram and KDE for sample 1\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(sample1, bins=20, density=True, alpha=0.5, color='blue', label='Histogram')\n",
    "x = np.linspace(min(sample1) - 2, max(sample1) + 2, 1000)\n",
    "kde = stats.gaussian_kde(sample1)\n",
    "plt.plot(x, kde(x), 'r-', linewidth=2, label='KDE')\n",
    "plt.plot(x, stats.norm.pdf(x, loc=5, scale=1.5), 'g--', linewidth=2, label='True PDF')\n",
    "plt.grid(True)\n",
    "plt.title('Sample 1: N(5, 1.5²)', fontsize=14)\n",
    "plt.xlabel('Value', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "# Histogram and KDE for sample 2\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(sample2, bins=20, density=True, alpha=0.5, color='green', label='Histogram')\n",
    "x = np.linspace(min(sample2) - 2, max(sample2) + 2, 1000)\n",
    "kde = stats.gaussian_kde(sample2)\n",
    "plt.plot(x, kde(x), 'r-', linewidth=2, label='KDE')\n",
    "plt.plot(x, stats.norm.pdf(x, loc=6, scale=2), 'b--', linewidth=2, label='True PDF')\n",
    "plt.grid(True)\n",
    "plt.title('Sample 2: N(6, 2²)', fontsize=14)\n",
    "plt.xlabel('Value', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ## 8. Additional Resources\n",
    "# \n",
    "# - [SciPy Documentation](https://docs.scipy.org/doc/scipy/reference/)\n",
    "# - [SciPy Lectures](https://scipy-lectures.org/)\n",
    "# - [SciPy Cookbook](https://scipy-cookbook.readthedocs.io/)\n",
    "# - [Scientific Python Crash Course](https://github.com/rougier/scipy-crash-course)\n",
    "# - [SciPy GitHub Repository](https://github.com/scipy/scipy)\n",
    "# - [Python for Scientific Computing](https://aaltoscicomp.github.io/python-for-scicomp/)\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
