{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy: The Foundation of Scientific Computing in Python\n",
    "\n",
    "## Introduction\n",
    "\n",
    "NumPy (Numerical Python) is the fundamental package for scientific computing in Python. It provides:\n",
    "\n",
    "- A powerful N-dimensional array object\n",
    "- Sophisticated broadcasting functions\n",
    "- Tools for integrating C/C++ and Fortran code\n",
    "- Useful linear algebra, Fourier transform, and random number capabilities\n",
    "\n",
    "This tutorial will introduce you to the most essential NumPy concepts and functions that are widely used in machine learning and data science projects.\n",
    "\n",
    "**Source:** [NumPy Documentation](https://numpy.org/doc/stable/) and [numpy-ml](https://github.com/ddbourgin/numpy-ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why NumPy?\n",
    "\n",
    "You can do numerical calculations using pure Python. In the beginning, you might think Python is fast enough, but once your data gets large, you'll start to notice slow downs.\n",
    "\n",
    "One of the main reasons to use NumPy is because it's **fast**. Behind the scenes, the code has been optimized to run using C, which is another programming language that can do things much faster than Python.\n",
    "\n",
    "The benefit of this being behind the scenes is you don't need to know any C to take advantage of it. You can write your numerical computations in Python using NumPy and get the added speed benefits.\n",
    "\n",
    "### Key Advantages of NumPy:\n",
    "\n",
    "1. **Performance**: NumPy arrays are stored in contiguous memory blocks, making operations much faster than with Python lists\n",
    "2. **Vectorization**: Perform operations on entire arrays without explicit loops\n",
    "3. **Broadcasting**: Efficiently perform operations between arrays of different shapes\n",
    "4. **Memory Efficiency**: NumPy arrays use less memory than Python lists for the same data\n",
    "5. **Integration**: Seamlessly works with other scientific Python libraries like SciPy, Pandas, and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Let's demonstrate the speed difference between NumPy and Python lists\n",
    "size = 1000000\n",
    "\n",
    "# Python list\n",
    "start_time = time.time()\n",
    "python_list = list(range(size))\n",
    "python_list = [x * 2 for x in python_list]\n",
    "python_time = time.time() - start_time\n",
    "\n",
    "# NumPy array\n",
    "start_time = time.time()\n",
    "numpy_array = np.arange(size)\n",
    "numpy_array = numpy_array * 2\n",
    "numpy_time = time.time() - start_time\n",
    "\n",
    "print(f\"Python list operation time: {python_time:.6f} seconds\")\n",
    "print(f\"NumPy array operation time: {numpy_time:.6f} seconds\")\n",
    "print(f\"NumPy is {python_time/numpy_time:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NumPy Arrays: The Building Blocks\n",
    "\n",
    "NumPy arrays are the core data structure in NumPy. They are similar to Python lists but with added functionality and performance benefits.\n",
    "\n",
    "### Concept: N-dimensional Arrays\n",
    "\n",
    "NumPy arrays can be one-dimensional (vectors), two-dimensional (matrices), or higher-dimensional. This flexibility allows NumPy to represent complex data structures efficiently.\n",
    "\n",
    "- **1D array**: A vector with a single axis\n",
    "- **2D array**: A matrix with rows and columns\n",
    "- **3D array**: A cube with depth, rows, and columns\n",
    "- **N-D array**: An array with N axes\n",
    "\n",
    "### 1.1 Creating NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# From Python lists\n",
    "array_1d = np.array([1, 2, 3, 4, 5])  # 1D array (vector)\n",
    "array_2d = np.array([[1, 2, 3], [4, 5, 6]])  # 2D array (matrix)\n",
    "array_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # 3D array\n",
    "\n",
    "print(\"1D array:\")\n",
    "print(array_1d)\n",
    "print(\"Shape:\", array_1d.shape)  # (5,) - 5 elements in 1 dimension\n",
    "print(\"Dimensions:\", array_1d.ndim)  # 1 dimension\n",
    "print()\n",
    "\n",
    "print(\"2D array:\")\n",
    "print(array_2d)\n",
    "print(\"Shape:\", array_2d.shape)  # (2, 3) - 2 rows, 3 columns\n",
    "print(\"Dimensions:\", array_2d.ndim)  # 2 dimensions\n",
    "print()\n",
    "\n",
    "print(\"3D array:\")\n",
    "print(array_3d)\n",
    "print(\"Shape:\", array_3d.shape)  # (2, 2, 2) - 2 blocks, 2 rows, 2 columns\n",
    "print(\"Dimensions:\", array_3d.ndim)  # 3 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Array Creation Functions\n",
    "\n",
    "NumPy provides various functions to create arrays with specific patterns or properties. These functions are essential for initializing data structures efficiently without manually specifying each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating arrays with specific values\n",
    "zeros = np.zeros((3, 4))  # 3x4 array of zeros\n",
    "ones = np.ones((2, 3, 4))  # 2x3x4 array of ones\n",
    "full = np.full((2, 2), 7)  # 2x2 array filled with 7\n",
    "\n",
    "# Creating sequences\n",
    "arange = np.arange(0, 10, 2)  # [0, 2, 4, 6, 8]\n",
    "linspace = np.linspace(0, 1, 5)  # 5 evenly spaced values from 0 to 1\n",
    "\n",
    "# Random arrays\n",
    "random_uniform = np.random.random((2, 3))  # 2x3 array of random values between 0 and 1\n",
    "random_normal = np.random.normal(0, 1, (2, 3))  # 2x3 array from normal distribution (mean=0, std=1)\n",
    "random_integers = np.random.randint(0, 10, (3, 3))  # 3x3 array of random integers from 0 to 9\n",
    "\n",
    "# Identity matrix\n",
    "identity = np.eye(3)  # 3x3 identity matrix\n",
    "\n",
    "print(\"Zeros array:\")\n",
    "print(zeros)\n",
    "print()\n",
    "\n",
    "print(\"Sequence with arange:\")\n",
    "print(arange)\n",
    "print()\n",
    "\n",
    "print(\"Evenly spaced values with linspace:\")\n",
    "print(linspace)\n",
    "print()\n",
    "\n",
    "print(\"Random integers:\")\n",
    "print(random_integers)\n",
    "print()\n",
    "\n",
    "print(\"Identity matrix:\")\n",
    "print(identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Array Attributes and Data Types\n",
    "\n",
    "NumPy arrays have several attributes that provide information about their structure. Understanding these attributes is crucial for working with arrays effectively.\n",
    "\n",
    "- **shape**: The dimensions of the array (tuple of integers)\n",
    "- **ndim**: Number of dimensions (axes)\n",
    "- **size**: Total number of elements\n",
    "- **dtype**: Data type of the elements\n",
    "- **itemsize**: Size in bytes of each element\n",
    "\n",
    "NumPy supports various data types, allowing for memory optimization and precise numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with a specific data type\n",
    "int_array = np.array([1, 2, 3], dtype=np.int32)\n",
    "float_array = np.array([1, 2, 3], dtype=np.float64)\n",
    "\n",
    "# Examine array attributes\n",
    "array = np.random.randint(0, 10, (3, 4))\n",
    "\n",
    "print(\"Array:\")\n",
    "print(array)\n",
    "print(\"Shape:\", array.shape)  # (3, 4)\n",
    "print(\"Dimensions:\", array.ndim)  # 2\n",
    "print(\"Size (total elements):\", array.size)  # 12\n",
    "print(\"Data type:\", array.dtype)  # int64\n",
    "print(\"Item size (bytes):\", array.itemsize)  # 8 bytes for int64\n",
    "print(\"Total memory used (bytes):\", array.nbytes)  # 96 bytes (12 elements * 8 bytes)\n",
    "\n",
    "# Compare memory usage of different data types\n",
    "print(\"\\nMemory usage comparison:\")\n",
    "print(f\"int32 array itemsize: {int_array.itemsize} bytes\")\n",
    "print(f\"float64 array itemsize: {float_array.itemsize} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Array Indexing and Slicing\n",
    "\n",
    "### Concept: Array Indexing\n",
    "\n",
    "NumPy arrays can be indexed similarly to Python lists, but with extended capabilities for multi-dimensional arrays. Understanding indexing is essential for accessing and manipulating specific elements or subsets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D array for demonstration\n",
    "arr_2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "print(\"Original 2D array:\")\n",
    "print(arr_2d)\n",
    "print()\n",
    "\n",
    "# Indexing single elements\n",
    "print(\"Element at row 0, column 1:\", arr_2d[0, 1])  # 2\n",
    "print(\"Element at row 2, column 3:\", arr_2d[2, 3])  # 12\n",
    "print()\n",
    "\n",
    "# Slicing rows and columns\n",
    "print(\"First row:\")\n",
    "print(arr_2d[0])  # [1, 2, 3, 4]\n",
    "print()\n",
    "\n",
    "print(\"First column:\")\n",
    "print(arr_2d[:, 0])  # [1, 5, 9]\n",
    "print()\n",
    "\n",
    "print(\"Rows 0-1, Columns 1-3:\")\n",
    "print(arr_2d[0:2, 1:4])  # [[2, 3, 4], [6, 7, 8]]\n",
    "print()\n",
    "\n",
    "# Advanced indexing\n",
    "print(\"Specific elements using index arrays:\")\n",
    "rows = np.array([0, 2])\n",
    "cols = np.array([1, 3])\n",
    "print(arr_2d[rows, cols])  # [2, 12] - elements at (0,1) and (2,3)\n",
    "print()\n",
    "\n",
    "print(\"Boolean indexing - elements greater than 5:\")\n",
    "print(arr_2d[arr_2d > 5])  # [6, 7, 8, 9, 10, 11, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Views vs. Copies\n",
    "\n",
    "When slicing NumPy arrays, it's important to understand the difference between views and copies. This concept is crucial for memory efficiency and avoiding unexpected behavior when modifying arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array\n",
    "original = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Create a view (shares the same data)\n",
    "view = original[1:4]  # [2, 3, 4]\n",
    "print(\"Original array:\", original)\n",
    "print(\"View:\", view)\n",
    "\n",
    "# Modify the view\n",
    "view[0] = 10\n",
    "print(\"\\nAfter modifying view:\")\n",
    "print(\"Original array:\", original)  # [1, 10, 3, 4, 5] - original is modified\n",
    "print(\"View:\", view)  # [10, 3, 4]\n",
    "\n",
    "# Create a copy (independent data)\n",
    "original = np.array([1, 2, 3, 4, 5])  # Reset original\n",
    "copy = original[1:4].copy()  # [2, 3, 4]\n",
    "print(\"\\nOriginal array:\", original)\n",
    "print(\"Copy:\", copy)\n",
    "\n",
    "# Modify the copy\n",
    "copy[0] = 10\n",
    "print(\"\\nAfter modifying copy:\")\n",
    "print(\"Original array:\", original)  # [1, 2, 3, 4, 5] - original is unchanged\n",
    "print(\"Copy:\", copy)  # [10, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Array Reshaping and Manipulation\n",
    "\n",
    "### Concept: Reshaping Arrays\n",
    "\n",
    "Reshaping allows you to change the dimensions of an array without changing its data. This is particularly useful when preparing data for machine learning algorithms that expect specific input shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1D array\n",
    "arr = np.arange(12)  # [0, 1, 2, ..., 11]\n",
    "print(\"Original 1D array:\")\n",
    "print(arr)\n",
    "print(\"Shape:\", arr.shape)  # (12,)\n",
    "print()\n",
    "\n",
    "# Reshape to 2D array (3 rows, 4 columns)\n",
    "arr_2d = arr.reshape(3, 4)\n",
    "print(\"Reshaped to 3x4:\")\n",
    "print(arr_2d)\n",
    "print(\"Shape:\", arr_2d.shape)  # (3, 4)\n",
    "print()\n",
    "\n",
    "# Reshape to 2D array (4 rows, 3 columns)\n",
    "arr_2d_alt = arr.reshape(4, 3)\n",
    "print(\"Reshaped to 4x3:\")\n",
    "print(arr_2d_alt)\n",
    "print(\"Shape:\", arr_2d_alt.shape)  # (4, 3)\n",
    "print()\n",
    "\n",
    "# Reshape to 3D array (2 blocks, 2 rows, 3 columns)\n",
    "arr_3d = arr.reshape(2, 2, 3)\n",
    "print(\"Reshaped to 2x2x3:\")\n",
    "print(arr_3d)\n",
    "print(\"Shape:\", arr_3d.shape)  # (2, 2, 3)\n",
    "print()\n",
    "\n",
    "# Using -1 to automatically calculate one dimension\n",
    "arr_auto = arr.reshape(3, -1)  # 3 rows, columns calculated automatically\n",
    "print(\"Reshaped with automatic column calculation:\")\n",
    "print(arr_auto)\n",
    "print(\"Shape:\", arr_auto.shape)  # (3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Array Manipulation\n",
    "\n",
    "NumPy provides various functions to manipulate arrays, such as concatenating, splitting, and transposing. These operations are essential for data preprocessing and feature engineering in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample arrays\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Array a:\")\n",
    "print(a)\n",
    "print(\"\\nArray b:\")\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "# Concatenation\n",
    "vertical_stack = np.vstack((a, b))  # Stack vertically (rows)\n",
    "horizontal_stack = np.hstack((a, b))  # Stack horizontally (columns)\n",
    "\n",
    "print(\"Vertical stack (vstack):\")\n",
    "print(vertical_stack)\n",
    "print(\"Shape:\", vertical_stack.shape)  # (4, 2)\n",
    "print()\n",
    "\n",
    "print(\"Horizontal stack (hstack):\")\n",
    "print(horizontal_stack)\n",
    "print(\"Shape:\", horizontal_stack.shape)  # (2, 4)\n",
    "print()\n",
    "\n",
    "# Splitting\n",
    "arr = np.arange(16).reshape(4, 4)\n",
    "print(\"Original array for splitting:\")\n",
    "print(arr)\n",
    "print()\n",
    "\n",
    "# Split horizontally (by rows)\n",
    "row_split = np.vsplit(arr, 2)  # Split into 2 arrays along rows\n",
    "print(\"Split by rows (vsplit):\")\n",
    "print(\"First part:\")\n",
    "print(row_split[0])\n",
    "print(\"Second part:\")\n",
    "print(row_split[1])\n",
    "print()\n",
    "\n",
    "# Split vertically (by columns)\n",
    "col_split = np.hsplit(arr, 2)  # Split into 2 arrays along columns\n",
    "print(\"Split by columns (hsplit):\")\n",
    "print(\"First part:\")\n",
    "print(col_split[0])\n",
    "print(\"Second part:\")\n",
    "print(col_split[1])\n",
    "print()\n",
    "\n",
    "# Transpose\n",
    "arr = np.arange(6).reshape(2, 3)\n",
    "print(\"Original array:\")\n",
    "print(arr)\n",
    "print(\"Shape:\", arr.shape)  # (2, 3)\n",
    "print()\n",
    "\n",
    "transposed = arr.T  # Transpose rows and columns\n",
    "print(\"Transposed array:\")\n",
    "print(transposed)\n",
    "print(\"Shape:\", transposed.shape)  # (3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NumPy Mathematical Operations\n",
    "\n",
    "### Concept: Vectorization\n",
    "\n",
    "Vectorization is the process of performing operations on entire arrays without using explicit loops. This is one of the key features that makes NumPy so powerful and efficient. Vectorized operations are much faster than their loop-based counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "\n",
    "# Element-wise operations\n",
    "print(\"Element-wise addition:\", a + b)  # [6, 8, 10, 12]\n",
    "print(\"Element-wise subtraction:\", a - b)  # [-4, -4, -4, -4]\n",
    "print(\"Element-wise multiplication:\", a * b)  # [5, 12, 21, 32]\n",
    "print(\"Element-wise division:\", a / b)  # [0.2, 0.33, 0.43, 0.5]\n",
    "print(\"Element-wise power:\", a ** 2)  # [1, 4, 9, 16]\n",
    "print()\n",
    "\n",
    "# Comparison with Python loops\n",
    "def python_multiply(list1, list2):\n",
    "    result = []\n",
    "    for i in range(len(list1)):\n",
    "        result.append(list1[i] * list2[i])\n",
    "    return result\n",
    "\n",
    "# Time comparison for larger arrays\n",
    "size = 1000000\n",
    "large_a = np.random.random(size)\n",
    "large_b = np.random.random(size)\n",
    "large_list_a = large_a.tolist()\n",
    "large_list_b = large_b.tolist()\n",
    "\n",
    "# NumPy vectorized operation\n",
    "start_time = time.time()\n",
    "numpy_result = large_a * large_b\n",
    "numpy_time = time.time() - start_time\n",
    "print(f\"NumPy vectorized multiplication time: {numpy_time:.6f} seconds\")\n",
    "\n",
    "# Python loop (only for small subset to avoid long execution)\n",
    "subset_size = 10000  # Using smaller subset for loop demonstration\n",
    "start_time = time.time()\n",
    "python_result = python_multiply(large_list_a[:subset_size], large_list_b[:subset_size])\n",
    "python_time = time.time() - start_time\n",
    "print(f\"Python loop multiplication time (for {subset_size} elements): {python_time:.6f} seconds\")\n",
    "print(f\"Estimated time for full array: {python_time * (size/subset_size):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Broadcasting\n",
    "\n",
    "Broadcasting allows NumPy to work with arrays of different shapes when performing arithmetic operations. It's a powerful feature that simplifies code and makes it more efficient by avoiding unnecessary copies of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting examples\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])  # 2x3 array\n",
    "print(\"Array a (2x3):\")\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "# Broadcasting scalar\n",
    "print(\"Adding scalar 10 to each element:\")\n",
    "print(a + 10)  # Adds 10 to each element\n",
    "print()\n",
    "\n",
    "# Broadcasting 1D array to 2D array\n",
    "b = np.array([10, 20, 30])  # 1D array with 3 elements\n",
    "print(\"Array b (1D with 3 elements):\")\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "print(\"Adding b to each row of a:\")\n",
    "print(a + b)  # b is broadcast to shape (2, 3) and added to a\n",
    "print()\n",
    "\n",
    "# Broadcasting with column vector\n",
    "c = np.array([[100], [200]])  # 2x1 array (column vector)\n",
    "print(\"Array c (column vector 2x1):\")\n",
    "print(c)\n",
    "print()\n",
    "\n",
    "print(\"Adding c to each column of a:\")\n",
    "print(a + c)  # c is broadcast to shape (2, 3) and added to a\n",
    "print()\n",
    "\n",
    "# Visualizing how broadcasting works\n",
    "print(\"Broadcasting visualization:\")\n",
    "print(\"Original shapes:\")\n",
    "print(f\"a: {a.shape} (2x3)\")\n",
    "print(f\"b: {b.shape} (3,)\")\n",
    "print(f\"c: {c.shape} (2x1)\")\n",
    "print()\n",
    "print(\"During broadcasting:\")\n",
    "print(\"b is treated as:\")\n",
    "print(np.tile(b, (2, 1)))  # Equivalent to how b is broadcast\n",
    "print()\n",
    "print(\"c is treated as:\")\n",
    "print(np.tile(c, (1, 3)))  # Equivalent to how c is broadcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Aggregation Functions\n",
    "\n",
    "NumPy provides various functions to perform aggregation operations on arrays, such as sum, mean, min, max, etc. These functions are essential for data analysis and feature engineering in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D array\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"Array:\")\n",
    "print(arr)\n",
    "print()\n",
    "\n",
    "# Basic aggregation functions\n",
    "print(\"Sum of all elements:\", np.sum(arr))  # 45\n",
    "print(\"Mean of all elements:\", np.mean(arr))  # 5.0\n",
    "print(\"Minimum value:\", np.min(arr))  # 1\n",
    "print(\"Maximum value:\", np.max(arr))  # 9\n",
    "print(\"Standard deviation:\", np.std(arr))  # ~2.58\n",
    "print(\"Variance:\", np.var(arr))  # ~6.67\n",
    "print()\n",
    "\n",
    "# Aggregation along axes\n",
    "print(\"Sum along rows (axis=0):\")\n",
    "print(np.sum(arr, axis=0))  # [12, 15, 18] - sum of each column\n",
    "print()\n",
    "\n",
    "print(\"Sum along columns (axis=1):\")\n",
    "print(np.sum(arr, axis=1))  # [6, 15, 24] - sum of each row\n",
    "print()\n",
    "\n",
    "print(\"Mean along rows (axis=0):\")\n",
    "print(np.mean(arr, axis=0))  # [4., 5., 6.] - mean of each column\n",
    "print()\n",
    "\n",
    "print(\"Mean along columns (axis=1):\")\n",
    "print(np.mean(arr, axis=1))  # [2., 5., 8.] - mean of each row\n",
    "print()\n",
    "\n",
    "# Cumulative functions\n",
    "print(\"Cumulative sum along rows:\")\n",
    "print(np.cumsum(arr, axis=0))\n",
    "print()\n",
    "\n",
    "print(\"Cumulative sum along columns:\")\n",
    "print(np.cumsum(arr, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Universal Functions (ufuncs)\n",
    "\n",
    "Universal functions (ufuncs) are functions that operate element-wise on arrays. They are optimized for performance and are a key component of NumPy's computational capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array\n",
    "arr = np.array([0, np.pi/4, np.pi/2, np.pi])\n",
    "print(\"Array (in radians):\")\n",
    "print(arr)\n",
    "print()\n",
    "\n",
    "# Trigonometric functions\n",
    "print(\"Sine:\")\n",
    "print(np.sin(arr))  # [0., 0.7071, 1., 0.]\n",
    "print()\n",
    "\n",
    "print(\"Cosine:\")\n",
    "print(np.cos(arr))  # [1., 0.7071, 0., -1.]\n",
    "print()\n",
    "\n",
    "print(\"Tangent:\")\n",
    "print(np.tan(arr))  # [0., 1., inf, 0.]\n",
    "print()\n",
    "\n",
    "# Exponential and logarithmic functions\n",
    "arr = np.array([1, 2, 3, 4])\n",
    "print(\"Array:\")\n",
    "print(arr)\n",
    "print()\n",
    "\n",
    "print(\"Exponential (e^x):\")\n",
    "print(np.exp(arr))  # [2.7183, 7.3891, 20.0855, 54.5982]\n",
    "print()\n",
    "\n",
    "print(\"Natural logarithm (ln):\")\n",
    "print(np.log(arr))  # [0., 0.6931, 1.0986, 1.3863]\n",
    "print()\n",
    "\n",
    "print(\"Base-10 logarithm:\")\n",
    "print(np.log10(arr))  # [0., 0.301, 0.4771, 0.6021]\n",
    "print()\n",
    "\n",
    "print(\"Square root:\")\n",
    "print(np.sqrt(arr))  # [1., 1.4142, 1.7321, 2.]\n",
    "print()\n",
    "\n",
    "# Rounding functions\n",
    "arr = np.array([1.49, 1.51, 2.49, 2.51, -1.49, -1.51])\n",
    "print(\"Array:\")\n",
    "print(arr)\n",
    "print()\n",
    "\n",
    "print(\"Round to nearest integer:\")\n",
    "print(np.round(arr))  # [1., 2., 2., 3., -1., -2.]\n",
    "print()\n",
    "\n",
    "print(\"Ceiling (round up):\")\n",
    "print(np.ceil(arr))  # [2., 2., 3., 3., -1., -1.]\n",
    "print()\n",
    "\n",
    "print(\"Floor (round down):\")\n",
    "print(np.floor(arr))  # [1., 1., 2., 2., -2., -2.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Real-world Applications of NumPy in Machine Learning\n",
    "\n",
    "NumPy is the foundation for many machine learning algorithms and data processing tasks. Let's explore some real-world applications to see how NumPy is used in practice.\n",
    "\n",
    "### 3.1 Linear Regression from Scratch\n",
    "\n",
    "Linear regression is a fundamental machine learning algorithm that models the relationship between a dependent variable and one or more independent variables. Let's implement it using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "X = 2 * np.random.rand(100, 1)  # 100 random inputs between 0 and 2\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)  # y = 4 + 3X + noise\n",
    "\n",
    "# Add bias term (intercept)\n",
    "X_b = np.c_[np.ones((100, 1)), X]  # Add x0 = 1 to each instance\n",
    "\n",
    "# Closed-form solution using Normal Equation: θ = (X^T X)^(-1) X^T y\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "\n",
    "print(\"Estimated parameters:\")\n",
    "print(f\"Intercept: {theta_best[0][0]:.4f}\")\n",
    "print(f\"Slope: {theta_best[1][0]:.4f}\")\n",
    "print(f\"True parameters: Intercept = 4, Slope = 3\")\n",
    "\n",
    "# Make predictions\n",
    "X_new = np.array([[0], [2]])  # Min and max X values\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]  # Add x0 = 1 to each instance\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, alpha=0.6, label='Training data')\n",
    "plt.plot(X_new, y_predict, 'r-', linewidth=2, label='Linear regression model')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear Regression from Scratch using NumPy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Implement gradient descent\n",
    "def gradient_descent(X, y, learning_rate=0.1, n_iterations=1000):\n",
    "    m = len(X)  # Number of instances\n",
    "    n = X.shape[1]  # Number of features (including bias)\n",
    "    theta = np.random.randn(n, 1)  # Random initialization\n",
    "    \n",
    "    # Store theta history and cost history for visualization\n",
    "    theta_history = [theta.copy()]\n",
    "    cost_history = []\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        # Compute predictions\n",
    "        y_pred = X.dot(theta)\n",
    "        \n",
    "        # Compute error\n",
    "        error = y_pred - y\n",
    "        \n",
    "        # Compute gradient\n",
    "        gradients = (2/m) * X.T.dot(error)\n",
    "        \n",
    "        # Update parameters\n",
    "        theta = theta - learning_rate * gradients\n",
    "        \n",
    "        # Store theta and cost\n",
    "        theta_history.append(theta.copy())\n",
    "        cost = np.mean(error ** 2)  # Mean Squared Error\n",
    "        cost_history.append(cost)\n",
    "    \n",
    "    return theta, theta_history, cost_history\n",
    "\n",
    "# Run gradient descent\n",
    "theta_gd, theta_history, cost_history = gradient_descent(X_b, y, learning_rate=0.1, n_iterations=1000)\n",
    "\n",
    "print(\"\\nGradient Descent results:\")\n",
    "print(f\"Intercept: {theta_gd[0][0]:.4f}\")\n",
    "print(f\"Slope: {theta_gd[1][0]:.4f}\")\n",
    "\n",
    "# Plot cost history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost (MSE)')\n",
    "plt.title('Cost History during Gradient Descent')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Matrix Operations in Linear Regression\n",
    "\n",
    "In the linear regression example above, we used several NumPy matrix operations:\n",
    "\n",
    "1. **Matrix Multiplication** (`dot`): Used to compute predictions (X·θ) and gradients (X^T·error)\n",
    "2. **Matrix Transpose** (`T`): Used to compute X^T for the normal equation and gradient calculation\n",
    "3. **Matrix Inverse** (`linalg.inv`): Used to compute (X^T·X)^(-1) in the normal equation\n",
    "4. **Broadcasting**: Used when subtracting vectors and computing squared errors\n",
    "\n",
    "These operations are fundamental to many machine learning algorithms and demonstrate the power of NumPy for numerical computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Principal Component Analysis (PCA)\n",
    "\n",
    "Principal Component Analysis is a dimensionality reduction technique widely used in machine learning. Let's implement it using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Standardize the data (mean=0, std=1)\n",
    "X_std = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# Compute the covariance matrix\n",
    "cov_matrix = np.cov(X_std.T)\n",
    "print(\"Covariance matrix shape:\", cov_matrix.shape)  # (4, 4) for 4 features\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort eigenvectors by decreasing eigenvalues\n",
    "idx = eigenvalues.argsort()[::-1]\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "# Select the top 2 eigenvectors (principal components)\n",
    "W = eigenvectors[:, :2]\n",
    "\n",
    "# Transform the data to the new subspace\n",
    "X_pca = X_std.dot(W)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, target_name in enumerate(['Setosa', 'Versicolor', 'Virginica']):\n",
    "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], alpha=0.8, label=target_name)\n",
    "\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA of Iris Dataset (implemented with NumPy)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "print(\"Explained variance ratio:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"Principal Component {i+1}: {ratio:.4f} ({ratio*100:.2f}%)\")\n",
    "\n",
    "# Cumulative explained variance\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "print(\"\\nCumulative explained variance:\")\n",
    "for i, ratio in enumerate(cumulative_variance_ratio):\n",
    "    print(f\"First {i+1} components: {ratio:.4f} ({ratio*100:.2f}%)\")\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(eigenvalues) + 1), explained_variance_ratio, alpha=0.8, align='center',\n",
    "        label='Individual explained variance')\n",
    "plt.step(range(1, len(eigenvalues) + 1), cumulative_variance_ratio, where='mid',\n",
    "         label='Cumulative explained variance')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Eigendecomposition in PCA\n",
    "\n",
    "In the PCA example, we used NumPy's linear algebra capabilities to perform eigendecomposition of the covariance matrix. This is a fundamental operation in many machine learning algorithms, including PCA, spectral clustering, and factor analysis.\n",
    "\n",
    "The key steps in PCA are:\n",
    "\n",
    "1. **Standardize the data**: Center the data by subtracting the mean and scale by dividing by the standard deviation\n",
    "2. **Compute the covariance matrix**: Measure how features vary together\n",
    "3. **Compute eigenvalues and eigenvectors**: Find the principal directions in the data\n",
    "4. **Sort eigenvectors by eigenvalues**: Rank components by importance\n",
    "5. **Project data onto principal components**: Transform data to the new coordinate system\n",
    "\n",
    "NumPy's linear algebra module (`np.linalg`) provides efficient implementations of these operations, making it possible to implement complex algorithms like PCA with just a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 K-means Clustering\n",
    "\n",
    "K-means is a popular unsupervised learning algorithm for clustering data. Let's implement it from scratch using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=42)\n",
    "\n",
    "# Implement k-means clustering from scratch using NumPy:\n",
    "def kmeans(X, k, max_iters=100, tol=1e-4):\n",
    "    # Number of samples and features\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Randomly initialize k centroids\n",
    "    idx = np.random.choice(n_samples, k, replace=False)\n",
    "    centroids = X[idx, :]\n",
    "    \n",
    "    # Initialize cluster assignments\n",
    "    prev_centroids = np.zeros((k, n_features))\n",
    "    clusters = np.zeros(n_samples)\n",
    "    \n",
    "    # Store centroids history for visualization\n",
    "    centroids_history = [centroids.copy()]\n",
    "    \n",
    "    # Iterate until convergence or max iterations\n",
    "    for _ in range(max_iters):\n",
    "        # Assign each sample to the closest centroid\n",
    "        for i in range(n_samples):\n",
    "            # Calculate distance to each centroid\n",
    "            distances = np.sqrt(np.sum((X[i] - centroids) ** 2, axis=1))\n",
    "            # Assign to the closest centroid\n",
    "            clusters[i] = np.argmin(distances)\n",
    "        \n",
    "        # Store previous centroids\n",
    "        prev_centroids = centroids.copy()\n",
    "        \n",
    "        # Update centroids\n",
    "        for j in range(k):\n",
    "            # Get all points assigned to this cluster\n",
    "            cluster_points = X[clusters == j]\n",
    "            # Update centroid if cluster is not empty\n",
    "            if len(cluster_points) > 0:\n",
    "                centroids[j] = np.mean(cluster_points, axis=0)\n",
    "        \n",
    "        # Store current centroids\n",
    "        centroids_history.append(centroids.copy())\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.all(np.abs(centroids - prev_centroids) < tol):\n",
    "            break\n",
    "    \n",
    "    return clusters, centroids, centroids_history\n",
    "\n",
    "# Run k-means\n",
    "k = 4\n",
    "clusters, centroids, centroids_history = kmeans(X, k)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot original data with true labels\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis', alpha=0.7, s=40)\n",
    "plt.title('Original Data with True Labels')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot clustered data\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.7, s=40)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label='Centroids')\n",
    "plt.title('K-means Clustering Results')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize centroid movement during iterations\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['r', 'g', 'b', 'purple']\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.5, s=40)\n",
    "\n",
    "# Plot centroid paths\n",
    "for i in range(k):\n",
    "    # Extract centroid positions for this cluster across all iterations\n",
    "    centroid_path = np.array([centroids[i] for centroids in centroids_history])\n",
    "    \n",
    "    # Plot the path\n",
    "    plt.plot(centroid_path[:, 0], centroid_path[:, 1], c=colors[i], marker='o', \n",
    "             markersize=8, linewidth=2, alpha=0.7, label=f'Centroid {i+1} path')\n",
    "    \n",
    "    # Mark the final position\n",
    "    plt.scatter(centroid_path[-1, 0], centroid_path[-1, 1], c=colors[i], marker='X', s=200, edgecolor='black')\n",
    "\n",
    "plt.title('Centroid Movement during K-means Iterations')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Distance Calculations in K-means\n",
    "\n",
    "In the K-means implementation, we used NumPy's vectorized operations to efficiently calculate distances between points and centroids. The Euclidean distance between a point `x` and a centroid `c` is calculated as:\n",
    "\n",
    "$$d(x, c) = \\sqrt{\\sum_{i=1}^{n} (x_i - c_i)^2}$$\n",
    "\n",
    "In NumPy, this is implemented as:\n",
    "```python\n",
    "distances = np.sqrt(np.sum((X[i] - centroids) ** 2, axis=1))\n",
    "```\n",
    "\n",
    "This vectorized operation calculates the distance from a single point to all centroids simultaneously, which is much more efficient than using loops. This is a common pattern in NumPy-based machine learning implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Problems\n",
    "\n",
    "Now that you've learned the fundamentals of NumPy, try solving these practice problems to test your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Array Manipulation\n",
    "\n",
    "Create a 5x5 array of random integers between 1 and 100. Then:\n",
    "1. Extract the central 3x3 subarray\n",
    "2. Replace the corners of the original array with zeros\n",
    "3. Calculate the sum of each row and each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "import numpy as np\n",
    "\n",
    "# Create a 5x5 array of random integers between 1 and 100\n",
    "np.random.seed(42)  # For reproducibility\n",
    "arr = np.random.randint(1, 101, size=(5, 5))\n",
    "print(\"Original array:\")\n",
    "print(arr)\n",
    "print()\n",
    "\n",
    "# 1. Extract the central 3x3 subarray\n",
    "central = arr[1:4, 1:4]\n",
    "print(\"Central 3x3 subarray:\")\n",
    "print(central)\n",
    "print()\n",
    "\n",
    "# 2. Replace the corners of the original array with zeros\n",
    "arr_corners = arr.copy()\n",
    "arr_corners[0, 0] = 0  # Top-left\n",
    "arr_corners[0, -1] = 0  # Top-right\n",
    "arr_corners[-1, 0] = 0  # Bottom-left\n",
    "arr_corners[-1, -1] = 0  # Bottom-right\n",
    "print(\"Array with corners replaced by zeros:\")\n",
    "print(arr_corners)\n",
    "print()\n",
    "\n",
    "# 3. Calculate the sum of each row and each column\n",
    "row_sums = np.sum(arr, axis=1)\n",
    "col_sums = np.sum(arr, axis=0)\n",
    "print(\"Sum of each row:\")\n",
    "print(row_sums)\n",
    "print(\"\\nSum of each column:\")\n",
    "print(col_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Broadcasting and Vectorization\n",
    "\n",
    "1. Create a 4x3 array of random numbers\n",
    "2. Normalize each row so that it sums to 1 (hint: use broadcasting)\n",
    "3. Calculate the Euclidean distance between each row and the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create a 4x3 array of random numbers\n",
    "np.random.seed(42)  # For reproducibility\n",
    "arr = np.random.rand(4, 3)\n",
    "print(\"Original array:\")\n",
    "print(arr)\n",
    "print()\n",
    "\n",
    "# 2. Normalize each row so that it sums to 1\n",
    "row_sums = np.sum(arr, axis=1)\n",
    "normalized = arr / row_sums[:, np.newaxis]  # Broadcasting\n",
    "print(\"Normalized array (each row sums to 1):\")\n",
    "print(normalized)\n",
    "print(\"\\nVerify row sums:\")\n",
    "print(np.sum(normalized, axis=1))  # Should be all 1's\n",
    "print()\n",
    "\n",
    "# 3. Calculate the Euclidean distance between each row and the first row\n",
    "first_row = normalized[0]\n",
    "distances = np.sqrt(np.sum((normalized - first_row) ** 2, axis=1))\n",
    "print(\"Euclidean distances from first row:\")\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Implementing a Simple Neural Network Layer\n",
    "\n",
    "Implement a simple neural network forward pass for a single layer with the following steps:\n",
    "1. Create a weight matrix of shape (3, 4) with random values\n",
    "2. Create a bias vector of shape (3,) with random values\n",
    "3. Create an input matrix of shape (5, 4) with random values\n",
    "4. Compute the output using the formula: output = input @ weights.T + bias\n",
    "5. Apply a ReLU activation function: relu(x) = max(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Create a weight matrix of shape (3, 4) with random values\n",
    "weights = np.random.randn(3, 4)\n",
    "print(\"Weights shape:\", weights.shape)\n",
    "print(\"Weights:\")\n",
    "print(weights)\n",
    "print()\n",
    "\n",
    "# 2. Create a bias vector of shape (3,) with random values\n",
    "bias = np.random.randn(3)\n",
    "print(\"Bias shape:\", bias.shape)\n",
    "print(\"Bias:\", bias)\n",
    "print()\n",
    "\n",
    "# 3. Create an input matrix of shape (5, 4) with random values\n",
    "inputs = np.random.randn(5, 4)\n",
    "print(\"Inputs shape:\", inputs.shape)\n",
    "print(\"Inputs:\")\n",
    "print(inputs)\n",
    "print()\n",
    "\n",
    "# 4. Compute the output using the formula: output = input @ weights.T + bias\n",
    "# Note: @ is the matrix multiplication operator in Python 3.5+\n",
    "linear_output = inputs @ weights.T + bias\n",
    "print(\"Linear output shape:\", linear_output.shape)\n",
    "print(\"Linear output:\")\n",
    "print(linear_output)\n",
    "print()\n",
    "\n",
    "# 5. Apply a ReLU activation function: relu(x) = max(0, x)\n",
    "relu_output = np.maximum(0, linear_output)\n",
    "print(\"ReLU output shape:\", relu_output.shape)\n",
    "print(\"ReLU output:\")\n",
    "print(relu_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "To further enhance your NumPy skills, check out these resources:\n",
    "\n",
    "- [NumPy Documentation](https://numpy.org/doc/stable/)\n",
    "- [NumPy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)\n",
    "- [NumPy Tutorials](https://numpy.org/numpy-tutorials/)\n",
    "- [NumPy ML Implementations](https://github.com/ddbourgin/numpy-ml)\n",
    "- [From Python to NumPy](https://www.labri.fr/perso/nrougier/from-python-to-numpy/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
